{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314601d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:25.653417Z",
     "start_time": "2023-10-20T12:55:25.646418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a71d10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:31.527035Z",
     "start_time": "2023-10-20T12:55:31.513362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b682f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:45.380476Z",
     "start_time": "2023-10-20T12:55:38.145357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('nose', 'likelihood')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H1R', 'likelihood')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H2R', 'likelihood')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>...</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('tail', 'likelihood')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S2', 'likelihood')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "      <th>('S1', 'likelihood')</th>\n",
       "      <th>mouse_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444275</td>\n",
       "      <td>2.021118</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>1.981354</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>4.448181</td>\n",
       "      <td>4.355835</td>\n",
       "      <td>0.997916</td>\n",
       "      <td>0.535675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.670120</td>\n",
       "      <td>0.212906</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>0.595001</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>3.630341</td>\n",
       "      <td>2.596069</td>\n",
       "      <td>0.993003</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.439880</td>\n",
       "      <td>3.892548</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.945496</td>\n",
       "      <td>3.524902</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>1.928741</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>0.970154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798141</td>\n",
       "      <td>1.392517</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>2.681183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986211</td>\n",
       "      <td>3.590607</td>\n",
       "      <td>2.148987</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.703064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>5.919373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>4.751312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>6.556610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855469</td>\n",
       "      <td>1.921738</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>2.977997</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.981083</td>\n",
       "      <td>3.765533</td>\n",
       "      <td>2.638062</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.169312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>20.999176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>17.283508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>13.850159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.927261</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>1.823181</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>1.339661</td>\n",
       "      <td>2.253326</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>3.207214</td>\n",
       "      <td>5.388489</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>3.782471</td>\n",
       "      <td>2.128571</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>8.150452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.424469</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>4.226929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>1.342590</td>\n",
       "      <td>4.823639</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.945129</td>\n",
       "      <td>3.831635</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.461548</td>\n",
       "      <td>1.584595</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>3.117249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.385101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>-0.049561</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>12.412659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>9.379395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>6.598083</td>\n",
       "      <td>2.645782</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>7.575562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155914</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>-0.301575</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.308044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214752</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.073730</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.488098</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053497</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.064789</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>-0.496552</td>\n",
       "      <td>-1.002960</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('nose', 'likelihood')  ('H1R', 'x')  \\\n",
       "0             0.000000       0.000000                0.999969      0.000000   \n",
       "1             0.444275       2.021118                0.999950      0.536194   \n",
       "2             0.439880       3.892548                0.999945      0.945496   \n",
       "3             7.703064       0.000000                0.999765      5.919373   \n",
       "4            17.169312       0.000000                0.999855     20.999176   \n",
       "...                ...            ...                     ...           ...   \n",
       "1102495       1.339661       2.253326                0.999232      3.207214   \n",
       "1102496       1.342590       4.823639                0.999680      1.945129   \n",
       "1102497      12.412659       0.000000                0.999622      9.379395   \n",
       "1102498       0.000000       0.000000                0.999570      0.000000   \n",
       "1102499       0.000000      -0.488098                0.999951      0.000000   \n",
       "\n",
       "         ('H1R', 'y')  ('H1R', 'likelihood')  ('H2R', 'x')  ('H2R', 'y')  \\\n",
       "0            0.000000               0.999760      0.000000      0.000000   \n",
       "1            1.981354               0.999568      4.448181      4.355835   \n",
       "2            3.524902               0.999638      1.928741      0.726379   \n",
       "3            0.000000               0.999534      4.751312      0.000000   \n",
       "4            0.000000               0.999252     17.283508      0.000000   \n",
       "...               ...                    ...           ...           ...   \n",
       "1102495      5.388489               0.999924      3.782471      2.128571   \n",
       "1102496      3.831635               0.999842      0.461548      1.584595   \n",
       "1102497      0.000000               0.999950      6.598083      2.645782   \n",
       "1102498      0.000000               0.999939      0.000000      0.000000   \n",
       "1102499     -0.053497               0.999773      0.000000      0.000000   \n",
       "\n",
       "         ('H2R', 'likelihood')  ('H1L', 'x')  ...  ('tail', 'x')  \\\n",
       "0                     0.996968      0.000000  ...       0.000000   \n",
       "1                     0.997916      0.535675  ...       1.670120   \n",
       "2                     0.999153      0.970154  ...       0.798141   \n",
       "3                     0.999468      6.556610  ...       1.855469   \n",
       "4                     0.998945     13.850159  ...       0.000000   \n",
       "...                        ...           ...  ...            ...   \n",
       "1102495               0.999492      8.150452  ...       0.582886   \n",
       "1102496               0.999562      3.117249  ...       0.348389   \n",
       "1102497               0.999656      7.575562  ...      -0.155914   \n",
       "1102498               0.999616      0.000000  ...       0.000000   \n",
       "1102499               0.998583      0.000000  ...       0.000000   \n",
       "\n",
       "         ('tail', 'y')  ('tail', 'likelihood')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0             0.000000                0.998689     0.000000     0.000000   \n",
       "1             0.212906                0.999059     0.595001     0.076477   \n",
       "2             1.392517                0.999419     2.681183     0.000000   \n",
       "3             1.921738                0.999285     2.977997     0.041992   \n",
       "4             4.927261                0.999156     0.000000     0.000000   \n",
       "...                ...                     ...          ...          ...   \n",
       "1102495       0.000000                0.999563     0.424469     0.375305   \n",
       "1102496       0.000000                0.999529     0.385101     0.000000   \n",
       "1102497      -1.260956                0.999215     0.496552    -0.301575   \n",
       "1102498      -0.214752                0.999225     0.000000    -0.073730   \n",
       "1102499      -1.064789                0.999358    -0.496552    -1.002960   \n",
       "\n",
       "         ('S2', 'likelihood')  ('S1', 'x')  ('S1', 'y')  ('S1', 'likelihood')  \\\n",
       "0                    0.994912     0.000000     0.000000              0.995648   \n",
       "1                    0.996069     3.630341     2.596069              0.993003   \n",
       "2                    0.986211     3.590607     2.148987              0.987800   \n",
       "3                    0.981083     3.765533     2.638062              0.994152   \n",
       "4                    0.983985     1.823181     0.067993              0.995609   \n",
       "...                       ...          ...          ...                   ...   \n",
       "1102495              0.998793     4.226929     0.000000              0.998882   \n",
       "1102496              0.998716     0.232422    -0.049561              0.998840   \n",
       "1102497              0.999035     0.308044     0.000000              0.998980   \n",
       "1102498              0.998865     0.000000     0.000000              0.998603   \n",
       "1102499              0.999527     0.000000     0.000000              0.998710   \n",
       "\n",
       "         mouse_no  \n",
       "0            11.4  \n",
       "1            11.4  \n",
       "2            11.4  \n",
       "3            11.4  \n",
       "4            11.4  \n",
       "...           ...  \n",
       "1102495      88.3  \n",
       "1102496      88.3  \n",
       "1102497      88.3  \n",
       "1102498      88.3  \n",
       "1102499      88.3  \n",
       "\n",
       "[1102500 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"C:/Users/Kieran/Documents/Master Thesis Data/Datasets/ChangeCoords\"\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "        \n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data = data.drop(columns = ['frame_number'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c90502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:24.250214Z",
     "start_time": "2023-10-20T12:56:24.236867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 25 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b49113e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:30.971456Z",
     "start_time": "2023-10-20T12:56:30.957509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, seq_size, dataframe, pred_window):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device      = device\n",
    "        self.seq_size    = seq_size\n",
    "        self.dataframe   = dataframe\n",
    "        self.pred_window = pred_window\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.seq_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[idx:idx + self.seq_size].values, dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[idx + self.pred_window:idx + self.seq_size + self.pred_window].values, dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0311a319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:38.576397Z",
     "start_time": "2023-10-20T12:56:38.233122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, seq_size, train_data, pred_window)\n",
    "val_dataset = SeqDataset(device, seq_size, val_data, pred_window)\n",
    "test_dataset = SeqDataset(device, seq_size, test_data, pred_window)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "549e679c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:05.842633Z",
     "start_time": "2023-10-20T13:22:05.833632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, int(hidden_size/2), layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.gru2      = nn.GRU(int(hidden_size/2), hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence)\n",
    "        \n",
    "        hidden_seq, hidden_state = self.gru2(hidden_seq)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74f0e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:12.646245Z",
     "start_time": "2023-10-20T13:22:12.523793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 43\n",
      "Output size: 28\n",
      "Model(\n",
      "  (gru): GRU(43, 8, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (gru2): GRU(8, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8050171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:34:55.248289Z",
     "start_time": "2023-10-20T13:22:19.431166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:54<00:00, 72.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10618.8135\n",
      "Val loss: 7843.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [03:28<00:00, 60.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6390.8817\n",
      "Val loss: 5273.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [03:08<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3782.8825\n",
      "Val loss: 2660.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:56<00:00, 71.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2184.4513\n",
      "Val loss: 2075.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [03:30<00:00, 60.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1954.3818\n",
      "Val loss: 1952.9237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [03:15<00:00, 64.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1893.6088\n",
      "Val loss: 1895.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:55<00:00, 72.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1821.7937\n",
      "Val loss: 1840.7069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:33<00:00, 82.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1695.3324\n",
      "Val loss: 1755.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:16<00:00, 92.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1598.9307\n",
      "Val loss: 1759.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████| 12656/12656 [02:17<00:00, 91.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1526.6388\n",
      "Val loss: 1714.4685\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"model_2_gru_reverse.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c48716-54f6-4978-b1f4-47dfd3c671a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (gru2): GRU(16, 8, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=8, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_2_gru.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "294297b2-da36-46bb-9658-cab24e82ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:35<00:00, 94.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1923.3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0deb1571-732c-450f-9a8d-397e1101d3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 8, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (gru2): GRU(8, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"model_2_gru_reverse.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2f04702-4683-4c4d-89c9-0bf013ed8778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:30<00:00, 110.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1213.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c6a59-4481-47f1-bad1-2f4d916680f7",
   "metadata": {},
   "source": [
    "### Longer sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008daa88-7fc7-4517-affc-4bf1a63b8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 50 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 25\n",
    "shift_size     = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458da445-5392-4a1e-a815-c1ac59275faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, dataframe, seq_size, pred_window, shift_size):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.seq_size = seq_size  # Input sequence length\n",
    "        self.shift_size = 25  # Shift for the start of each new sequence\n",
    "        self.pred_window = pred_window  # Additional frames for prediction\n",
    "        self.dataframe = dataframe\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        # The total number of sequences is adjusted for shifting the sequence start by self.shift_size\n",
    "        return (len(self.dataframe) - self.seq_size - self.pred_window) // self.shift_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the actual starting index for the sequence based on the shift size\n",
    "        start_idx = idx * self.shift_size\n",
    "        end_idx = start_idx + self.seq_size\n",
    "        target_end_idx = end_idx + self.pred_window\n",
    "\n",
    "        # Ensure we don't exceed the bounds of the dataframe\n",
    "        if target_end_idx > len(self.dataframe):\n",
    "            target_end_idx = len(self.dataframe)\n",
    "            end_idx = target_end_idx - self.pred_window\n",
    "\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[start_idx:end_idx].values,\n",
    "                              dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[start_idx+self.pred_window:target_end_idx].values,\n",
    "                                  dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea39e2ba-6951-4264-98e8-6ecbf8aafb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, train_data, seq_size, pred_window, shift_size)\n",
    "val_dataset = SeqDataset(device, val_data, seq_size, pred_window, shift_size)\n",
    "test_dataset = SeqDataset(device, test_data, seq_size, pred_window, shift_size)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324a4c26-45f6-45ca-9fb6-b92bac02d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.gru2      = nn.GRU(hidden_size, int(hidden_size/2), layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(int(hidden_size/2), output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence)\n",
    "        \n",
    "        hidden_seq, hidden_state = self.gru2(hidden_seq)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc3d491-31da-4aa3-8f6a-21f9385a0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 43\n",
      "Output size: 28\n",
      "Model(\n",
      "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (gru2): GRU(16, 8, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=8, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a869ab-8581-4f08-8556-6fafd85e782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:19<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 140.0225\n",
      "Val loss: 240.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:19<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.9302\n",
      "Val loss: 240.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:18<00:00, 26.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8090\n",
      "Val loss: 240.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:18<00:00, 27.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8533\n",
      "Val loss: 240.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 29.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8808\n",
      "Val loss: 240.0738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:17<00:00, 29.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8033\n",
      "Val loss: 240.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:17<00:00, 29.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8003\n",
      "Val loss: 240.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7356\n",
      "Val loss: 240.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:13<00:00, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8230\n",
      "Val loss: 240.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:13<00:00, 37.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7711\n",
      "Val loss: 240.0972\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"C:/Users/Kieran/Documents/Master Thesis Data/Models/model_cc_2_gru_pred_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb75a6a4-f63a-4c0f-9cef-47cb38ecc9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (gru2): GRU(16, 8, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=8, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"C:/Users/Kieran/Documents/Master Thesis Data/Models/model_cc_2_gru_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f76a6e-6c61-4719-9520-2f4a0baa712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [00:02<00:00, 45.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 120.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
