{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314601d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:25.653417Z",
     "start_time": "2023-10-20T12:55:25.646418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a71d10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:31.527035Z",
     "start_time": "2023-10-20T12:55:31.513362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b682f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:45.380476Z",
     "start_time": "2023-10-20T12:55:38.145357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('nose', 'likelihood')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H1R', 'likelihood')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H2R', 'likelihood')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>...</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('tail', 'likelihood')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S2', 'likelihood')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "      <th>('S1', 'likelihood')</th>\n",
       "      <th>mouse_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.281118</td>\n",
       "      <td>6.777963</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>-107.543587</td>\n",
       "      <td>-9.904076</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>-91.049674</td>\n",
       "      <td>-24.262784</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>-114.476969</td>\n",
       "      <td>...</td>\n",
       "      <td>136.551132</td>\n",
       "      <td>15.836794</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>58.663218</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>-428.453907</td>\n",
       "      <td>-57.731640</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-118.466293</td>\n",
       "      <td>5.164439</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>-104.771778</td>\n",
       "      <td>-11.426444</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>-92.801407</td>\n",
       "      <td>-25.102813</td>\n",
       "      <td>0.997916</td>\n",
       "      <td>-111.668127</td>\n",
       "      <td>...</td>\n",
       "      <td>139.580639</td>\n",
       "      <td>16.430253</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>62.608034</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>-432.897362</td>\n",
       "      <td>-57.456968</td>\n",
       "      <td>0.993003</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.116147</td>\n",
       "      <td>3.743272</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>-103.840623</td>\n",
       "      <td>-12.463020</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>-91.015857</td>\n",
       "      <td>-23.573421</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>-108.146772</td>\n",
       "      <td>...</td>\n",
       "      <td>142.442255</td>\n",
       "      <td>12.872289</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>64.691238</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>0.986211</td>\n",
       "      <td>-437.910362</td>\n",
       "      <td>-49.581608</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-118.168901</td>\n",
       "      <td>10.876589</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>-103.922190</td>\n",
       "      <td>-6.807094</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>-90.473196</td>\n",
       "      <td>-18.974423</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>-108.043361</td>\n",
       "      <td>...</td>\n",
       "      <td>144.586701</td>\n",
       "      <td>9.035496</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>66.998246</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>0.981083</td>\n",
       "      <td>-443.445989</td>\n",
       "      <td>-39.517151</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-129.872247</td>\n",
       "      <td>18.977417</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>-118.215160</td>\n",
       "      <td>4.053176</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>-101.756529</td>\n",
       "      <td>-10.320907</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>-117.468658</td>\n",
       "      <td>...</td>\n",
       "      <td>142.597915</td>\n",
       "      <td>6.642514</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>68.408748</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>-444.126056</td>\n",
       "      <td>-45.945764</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>-67.278284</td>\n",
       "      <td>-67.951573</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>-53.510518</td>\n",
       "      <td>-67.561356</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>-45.792688</td>\n",
       "      <td>-60.568728</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>-71.032565</td>\n",
       "      <td>...</td>\n",
       "      <td>112.339967</td>\n",
       "      <td>-39.013942</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>65.652483</td>\n",
       "      <td>-1.421085e-14</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>44.635680</td>\n",
       "      <td>-639.773663</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>-63.502359</td>\n",
       "      <td>-71.564452</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>-50.896190</td>\n",
       "      <td>-71.149798</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>-44.362936</td>\n",
       "      <td>-61.712636</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>-70.997425</td>\n",
       "      <td>...</td>\n",
       "      <td>112.415697</td>\n",
       "      <td>-38.871035</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>65.616523</td>\n",
       "      <td>-1.065814e-14</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>45.998709</td>\n",
       "      <td>-639.839548</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>-69.702519</td>\n",
       "      <td>-81.962860</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>-55.540755</td>\n",
       "      <td>-78.942856</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>-45.310777</td>\n",
       "      <td>-68.474218</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>-73.736269</td>\n",
       "      <td>...</td>\n",
       "      <td>111.575389</td>\n",
       "      <td>-37.813775</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>65.260951</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>45.910568</td>\n",
       "      <td>-640.098971</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>-69.750044</td>\n",
       "      <td>-81.922420</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>-55.586531</td>\n",
       "      <td>-78.910630</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>-45.350483</td>\n",
       "      <td>-68.447927</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>-73.774792</td>\n",
       "      <td>...</td>\n",
       "      <td>111.369144</td>\n",
       "      <td>-37.768235</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>65.197667</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>45.539315</td>\n",
       "      <td>-640.125490</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>-71.351181</td>\n",
       "      <td>-80.641039</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>-56.775624</td>\n",
       "      <td>-78.064403</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>-46.342748</td>\n",
       "      <td>-67.780047</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>-74.734211</td>\n",
       "      <td>...</td>\n",
       "      <td>109.901445</td>\n",
       "      <td>-38.826665</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>64.598714</td>\n",
       "      <td>-1.065814e-14</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>36.209816</td>\n",
       "      <td>-640.720939</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('nose', 'likelihood')  ('H1R', 'x')  \\\n",
       "0          -121.281118       6.777963                0.999969   -107.543587   \n",
       "1          -118.466293       5.164439                0.999950   -104.771778   \n",
       "2          -117.116147       3.743272                0.999945   -103.840623   \n",
       "3          -118.168901      10.876589                0.999765   -103.922190   \n",
       "4          -129.872247      18.977417                0.999855   -118.215160   \n",
       "...                ...            ...                     ...           ...   \n",
       "1102495     -67.278284     -67.951573                0.999232    -53.510518   \n",
       "1102496     -63.502359     -71.564452                0.999680    -50.896190   \n",
       "1102497     -69.702519     -81.962860                0.999622    -55.540755   \n",
       "1102498     -69.750044     -81.922420                0.999570    -55.586531   \n",
       "1102499     -71.351181     -80.641039                0.999951    -56.775624   \n",
       "\n",
       "         ('H1R', 'y')  ('H1R', 'likelihood')  ('H2R', 'x')  ('H2R', 'y')  \\\n",
       "0           -9.904076               0.999760    -91.049674    -24.262784   \n",
       "1          -11.426444               0.999568    -92.801407    -25.102813   \n",
       "2          -12.463020               0.999638    -91.015857    -23.573421   \n",
       "3           -6.807094               0.999534    -90.473196    -18.974423   \n",
       "4            4.053176               0.999252   -101.756529    -10.320907   \n",
       "...               ...                    ...           ...           ...   \n",
       "1102495    -67.561356               0.999924    -45.792688    -60.568728   \n",
       "1102496    -71.149798               0.999842    -44.362936    -61.712636   \n",
       "1102497    -78.942856               0.999950    -45.310777    -68.474218   \n",
       "1102498    -78.910630               0.999939    -45.350483    -68.447927   \n",
       "1102499    -78.064403               0.999773    -46.342748    -67.780047   \n",
       "\n",
       "         ('H2R', 'likelihood')  ('H1L', 'x')  ...  ('tail', 'x')  \\\n",
       "0                     0.996968   -114.476969  ...     136.551132   \n",
       "1                     0.997916   -111.668127  ...     139.580639   \n",
       "2                     0.999153   -108.146772  ...     142.442255   \n",
       "3                     0.999468   -108.043361  ...     144.586701   \n",
       "4                     0.998945   -117.468658  ...     142.597915   \n",
       "...                        ...           ...  ...            ...   \n",
       "1102495               0.999492    -71.032565  ...     112.339967   \n",
       "1102496               0.999562    -70.997425  ...     112.415697   \n",
       "1102497               0.999656    -73.736269  ...     111.575389   \n",
       "1102498               0.999616    -73.774792  ...     111.369144   \n",
       "1102499               0.998583    -74.734211  ...     109.901445   \n",
       "\n",
       "         ('tail', 'y')  ('tail', 'likelihood')  ('S2', 'x')   ('S2', 'y')  \\\n",
       "0            15.836794                0.998689    58.663218  3.552714e-15   \n",
       "1            16.430253                0.999059    62.608034  3.552714e-15   \n",
       "2            12.872289                0.999419    64.691238 -7.105427e-15   \n",
       "3             9.035496                0.999285    66.998246 -7.105427e-15   \n",
       "4             6.642514                0.999156    68.408748 -7.105427e-15   \n",
       "...                ...                     ...          ...           ...   \n",
       "1102495     -39.013942                0.999563    65.652483 -1.421085e-14   \n",
       "1102496     -38.871035                0.999529    65.616523 -1.065814e-14   \n",
       "1102497     -37.813775                0.999215    65.260951 -7.105427e-15   \n",
       "1102498     -37.768235                0.999225    65.197667  7.105427e-15   \n",
       "1102499     -38.826665                0.999358    64.598714 -1.065814e-14   \n",
       "\n",
       "         ('S2', 'likelihood')  ('S1', 'x')  ('S1', 'y')  ('S1', 'likelihood')  \\\n",
       "0                    0.994912  -428.453907   -57.731640              0.995648   \n",
       "1                    0.996069  -432.897362   -57.456968              0.993003   \n",
       "2                    0.986211  -437.910362   -49.581608              0.987800   \n",
       "3                    0.981083  -443.445989   -39.517151              0.994152   \n",
       "4                    0.983985  -444.126056   -45.945764              0.995609   \n",
       "...                       ...          ...          ...                   ...   \n",
       "1102495              0.998793    44.635680  -639.773663              0.998882   \n",
       "1102496              0.998716    45.998709  -639.839548              0.998840   \n",
       "1102497              0.999035    45.910568  -640.098971              0.998980   \n",
       "1102498              0.998865    45.539315  -640.125490              0.998603   \n",
       "1102499              0.999527    36.209816  -640.720939              0.998710   \n",
       "\n",
       "         mouse_no  \n",
       "0            11.4  \n",
       "1            11.4  \n",
       "2            11.4  \n",
       "3            11.4  \n",
       "4            11.4  \n",
       "...           ...  \n",
       "1102495      88.3  \n",
       "1102496      88.3  \n",
       "1102497      88.3  \n",
       "1102498      88.3  \n",
       "1102499      88.3  \n",
       "\n",
       "[1102500 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"C:/Users/Kieran/Documents/Master Thesis Data/Datasets/MouseDirectional\"\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "        \n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data = data.drop(columns = ['frame_number'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a785b79-9304-4d16-9002-f35298232989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>('H1L', 'y')</th>\n",
       "      <th>('H2L', 'x')</th>\n",
       "      <th>('H2L', 'y')</th>\n",
       "      <th>...</th>\n",
       "      <th>('B2L', 'x')</th>\n",
       "      <th>('B2L', 'y')</th>\n",
       "      <th>('B3L', 'x')</th>\n",
       "      <th>('B3L', 'y')</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.281118</td>\n",
       "      <td>6.777963</td>\n",
       "      <td>-107.543587</td>\n",
       "      <td>-9.904076</td>\n",
       "      <td>-91.049674</td>\n",
       "      <td>-24.262784</td>\n",
       "      <td>-114.476969</td>\n",
       "      <td>17.757493</td>\n",
       "      <td>-95.642332</td>\n",
       "      <td>29.419203</td>\n",
       "      <td>...</td>\n",
       "      <td>68.308038</td>\n",
       "      <td>57.202524</td>\n",
       "      <td>111.302323</td>\n",
       "      <td>39.594285</td>\n",
       "      <td>136.551132</td>\n",
       "      <td>15.836794</td>\n",
       "      <td>58.663218</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>-428.453907</td>\n",
       "      <td>-57.731640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-118.466293</td>\n",
       "      <td>5.164439</td>\n",
       "      <td>-104.771778</td>\n",
       "      <td>-11.426444</td>\n",
       "      <td>-92.801407</td>\n",
       "      <td>-25.102813</td>\n",
       "      <td>-111.668127</td>\n",
       "      <td>16.282128</td>\n",
       "      <td>-95.395779</td>\n",
       "      <td>27.423142</td>\n",
       "      <td>...</td>\n",
       "      <td>71.765439</td>\n",
       "      <td>56.764052</td>\n",
       "      <td>115.032002</td>\n",
       "      <td>39.768954</td>\n",
       "      <td>139.580639</td>\n",
       "      <td>16.430253</td>\n",
       "      <td>62.608034</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>-432.897362</td>\n",
       "      <td>-57.456968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.116147</td>\n",
       "      <td>3.743272</td>\n",
       "      <td>-103.840623</td>\n",
       "      <td>-12.463020</td>\n",
       "      <td>-91.015857</td>\n",
       "      <td>-23.573421</td>\n",
       "      <td>-108.146772</td>\n",
       "      <td>17.867068</td>\n",
       "      <td>-95.075329</td>\n",
       "      <td>27.651654</td>\n",
       "      <td>...</td>\n",
       "      <td>75.908466</td>\n",
       "      <td>54.183708</td>\n",
       "      <td>119.430075</td>\n",
       "      <td>36.769587</td>\n",
       "      <td>142.442255</td>\n",
       "      <td>12.872289</td>\n",
       "      <td>64.691238</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>-437.910362</td>\n",
       "      <td>-49.581608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-118.168901</td>\n",
       "      <td>10.876589</td>\n",
       "      <td>-103.922190</td>\n",
       "      <td>-6.807094</td>\n",
       "      <td>-90.473196</td>\n",
       "      <td>-18.974423</td>\n",
       "      <td>-108.043361</td>\n",
       "      <td>24.035569</td>\n",
       "      <td>-93.308834</td>\n",
       "      <td>32.225534</td>\n",
       "      <td>...</td>\n",
       "      <td>79.532210</td>\n",
       "      <td>50.372116</td>\n",
       "      <td>118.700687</td>\n",
       "      <td>31.844225</td>\n",
       "      <td>144.586701</td>\n",
       "      <td>9.035496</td>\n",
       "      <td>66.998246</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>-443.445989</td>\n",
       "      <td>-39.517151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-129.872247</td>\n",
       "      <td>18.977417</td>\n",
       "      <td>-118.215160</td>\n",
       "      <td>4.053176</td>\n",
       "      <td>-101.756529</td>\n",
       "      <td>-10.320907</td>\n",
       "      <td>-117.468658</td>\n",
       "      <td>30.129350</td>\n",
       "      <td>-100.656114</td>\n",
       "      <td>36.639027</td>\n",
       "      <td>...</td>\n",
       "      <td>79.262964</td>\n",
       "      <td>49.639693</td>\n",
       "      <td>116.723267</td>\n",
       "      <td>29.462425</td>\n",
       "      <td>142.597915</td>\n",
       "      <td>6.642514</td>\n",
       "      <td>68.408748</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>-444.126056</td>\n",
       "      <td>-45.945764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>-67.278284</td>\n",
       "      <td>-67.951573</td>\n",
       "      <td>-53.510518</td>\n",
       "      <td>-67.561356</td>\n",
       "      <td>-45.792688</td>\n",
       "      <td>-60.568728</td>\n",
       "      <td>-71.032565</td>\n",
       "      <td>-56.138913</td>\n",
       "      <td>-67.660236</td>\n",
       "      <td>-33.669516</td>\n",
       "      <td>...</td>\n",
       "      <td>107.977805</td>\n",
       "      <td>42.951319</td>\n",
       "      <td>118.008388</td>\n",
       "      <td>-8.684928</td>\n",
       "      <td>112.339967</td>\n",
       "      <td>-39.013942</td>\n",
       "      <td>65.652483</td>\n",
       "      <td>-1.421085e-14</td>\n",
       "      <td>44.635680</td>\n",
       "      <td>-639.773663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>-63.502359</td>\n",
       "      <td>-71.564452</td>\n",
       "      <td>-50.896190</td>\n",
       "      <td>-71.149798</td>\n",
       "      <td>-44.362936</td>\n",
       "      <td>-61.712636</td>\n",
       "      <td>-70.997425</td>\n",
       "      <td>-59.609619</td>\n",
       "      <td>-68.610977</td>\n",
       "      <td>-36.893957</td>\n",
       "      <td>...</td>\n",
       "      <td>107.948700</td>\n",
       "      <td>43.198371</td>\n",
       "      <td>118.149390</td>\n",
       "      <td>-8.204957</td>\n",
       "      <td>112.415697</td>\n",
       "      <td>-38.871035</td>\n",
       "      <td>65.616523</td>\n",
       "      <td>-1.065814e-14</td>\n",
       "      <td>45.998709</td>\n",
       "      <td>-639.839548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>-69.702519</td>\n",
       "      <td>-81.962860</td>\n",
       "      <td>-55.540755</td>\n",
       "      <td>-78.942856</td>\n",
       "      <td>-45.310777</td>\n",
       "      <td>-68.474218</td>\n",
       "      <td>-73.736269</td>\n",
       "      <td>-66.442908</td>\n",
       "      <td>-71.803595</td>\n",
       "      <td>-45.464528</td>\n",
       "      <td>...</td>\n",
       "      <td>108.147861</td>\n",
       "      <td>43.588136</td>\n",
       "      <td>118.030566</td>\n",
       "      <td>-7.391648</td>\n",
       "      <td>111.575389</td>\n",
       "      <td>-37.813775</td>\n",
       "      <td>65.260951</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>45.910568</td>\n",
       "      <td>-640.098971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>-69.750044</td>\n",
       "      <td>-81.922420</td>\n",
       "      <td>-55.586531</td>\n",
       "      <td>-78.910630</td>\n",
       "      <td>-45.350483</td>\n",
       "      <td>-68.447927</td>\n",
       "      <td>-73.774792</td>\n",
       "      <td>-66.400131</td>\n",
       "      <td>-71.829951</td>\n",
       "      <td>-45.422876</td>\n",
       "      <td>...</td>\n",
       "      <td>106.668777</td>\n",
       "      <td>44.425300</td>\n",
       "      <td>118.134399</td>\n",
       "      <td>-6.845362</td>\n",
       "      <td>111.369144</td>\n",
       "      <td>-37.768235</td>\n",
       "      <td>65.197667</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>45.539315</td>\n",
       "      <td>-640.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>-71.351181</td>\n",
       "      <td>-80.641039</td>\n",
       "      <td>-56.775624</td>\n",
       "      <td>-78.064403</td>\n",
       "      <td>-46.342748</td>\n",
       "      <td>-67.780047</td>\n",
       "      <td>-74.734211</td>\n",
       "      <td>-65.318413</td>\n",
       "      <td>-72.484002</td>\n",
       "      <td>-44.371714</td>\n",
       "      <td>...</td>\n",
       "      <td>107.304599</td>\n",
       "      <td>42.866750</td>\n",
       "      <td>116.712415</td>\n",
       "      <td>-7.447689</td>\n",
       "      <td>109.901445</td>\n",
       "      <td>-38.826665</td>\n",
       "      <td>64.598714</td>\n",
       "      <td>-1.065814e-14</td>\n",
       "      <td>36.209816</td>\n",
       "      <td>-640.720939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('H1R', 'x')  ('H1R', 'y')  \\\n",
       "0          -121.281118       6.777963   -107.543587     -9.904076   \n",
       "1          -118.466293       5.164439   -104.771778    -11.426444   \n",
       "2          -117.116147       3.743272   -103.840623    -12.463020   \n",
       "3          -118.168901      10.876589   -103.922190     -6.807094   \n",
       "4          -129.872247      18.977417   -118.215160      4.053176   \n",
       "...                ...            ...           ...           ...   \n",
       "1102495     -67.278284     -67.951573    -53.510518    -67.561356   \n",
       "1102496     -63.502359     -71.564452    -50.896190    -71.149798   \n",
       "1102497     -69.702519     -81.962860    -55.540755    -78.942856   \n",
       "1102498     -69.750044     -81.922420    -55.586531    -78.910630   \n",
       "1102499     -71.351181     -80.641039    -56.775624    -78.064403   \n",
       "\n",
       "         ('H2R', 'x')  ('H2R', 'y')  ('H1L', 'x')  ('H1L', 'y')  ('H2L', 'x')  \\\n",
       "0          -91.049674    -24.262784   -114.476969     17.757493    -95.642332   \n",
       "1          -92.801407    -25.102813   -111.668127     16.282128    -95.395779   \n",
       "2          -91.015857    -23.573421   -108.146772     17.867068    -95.075329   \n",
       "3          -90.473196    -18.974423   -108.043361     24.035569    -93.308834   \n",
       "4         -101.756529    -10.320907   -117.468658     30.129350   -100.656114   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "1102495    -45.792688    -60.568728    -71.032565    -56.138913    -67.660236   \n",
       "1102496    -44.362936    -61.712636    -70.997425    -59.609619    -68.610977   \n",
       "1102497    -45.310777    -68.474218    -73.736269    -66.442908    -71.803595   \n",
       "1102498    -45.350483    -68.447927    -73.774792    -66.400131    -71.829951   \n",
       "1102499    -46.342748    -67.780047    -74.734211    -65.318413    -72.484002   \n",
       "\n",
       "         ('H2L', 'y')  ...  ('B2L', 'x')  ('B2L', 'y')  ('B3L', 'x')  \\\n",
       "0           29.419203  ...     68.308038     57.202524    111.302323   \n",
       "1           27.423142  ...     71.765439     56.764052    115.032002   \n",
       "2           27.651654  ...     75.908466     54.183708    119.430075   \n",
       "3           32.225534  ...     79.532210     50.372116    118.700687   \n",
       "4           36.639027  ...     79.262964     49.639693    116.723267   \n",
       "...               ...  ...           ...           ...           ...   \n",
       "1102495    -33.669516  ...    107.977805     42.951319    118.008388   \n",
       "1102496    -36.893957  ...    107.948700     43.198371    118.149390   \n",
       "1102497    -45.464528  ...    108.147861     43.588136    118.030566   \n",
       "1102498    -45.422876  ...    106.668777     44.425300    118.134399   \n",
       "1102499    -44.371714  ...    107.304599     42.866750    116.712415   \n",
       "\n",
       "         ('B3L', 'y')  ('tail', 'x')  ('tail', 'y')  ('S2', 'x')  \\\n",
       "0           39.594285     136.551132      15.836794    58.663218   \n",
       "1           39.768954     139.580639      16.430253    62.608034   \n",
       "2           36.769587     142.442255      12.872289    64.691238   \n",
       "3           31.844225     144.586701       9.035496    66.998246   \n",
       "4           29.462425     142.597915       6.642514    68.408748   \n",
       "...               ...            ...            ...          ...   \n",
       "1102495     -8.684928     112.339967     -39.013942    65.652483   \n",
       "1102496     -8.204957     112.415697     -38.871035    65.616523   \n",
       "1102497     -7.391648     111.575389     -37.813775    65.260951   \n",
       "1102498     -6.845362     111.369144     -37.768235    65.197667   \n",
       "1102499     -7.447689     109.901445     -38.826665    64.598714   \n",
       "\n",
       "          ('S2', 'y')  ('S1', 'x')  ('S1', 'y')  \n",
       "0        3.552714e-15  -428.453907   -57.731640  \n",
       "1        3.552714e-15  -432.897362   -57.456968  \n",
       "2       -7.105427e-15  -437.910362   -49.581608  \n",
       "3       -7.105427e-15  -443.445989   -39.517151  \n",
       "4       -7.105427e-15  -444.126056   -45.945764  \n",
       "...               ...          ...          ...  \n",
       "1102495 -1.421085e-14    44.635680  -639.773663  \n",
       "1102496 -1.065814e-14    45.998709  -639.839548  \n",
       "1102497 -7.105427e-15    45.910568  -640.098971  \n",
       "1102498  7.105427e-15    45.539315  -640.125490  \n",
       "1102499 -1.065814e-14    36.209816  -640.720939  \n",
       "\n",
       "[1102500 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = data.filter(regex='x|y')\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f3a88-ae6a-4630-b5e2-05936e2ccf0a",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c90502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:24.250214Z",
     "start_time": "2023-10-20T12:56:24.236867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 25 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b49113e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:30.971456Z",
     "start_time": "2023-10-20T12:56:30.957509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, seq_size, dataframe, pred_window):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device      = device\n",
    "        self.seq_size    = seq_size\n",
    "        self.dataframe   = dataframe\n",
    "        self.pred_window = pred_window\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.seq_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[idx:idx + self.seq_size].values, dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[idx + self.pred_window:idx + self.seq_size + self.pred_window].values, dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0026de6d-f242-4941-90a4-2e2fafbe95f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>('H1L', 'y')</th>\n",
       "      <th>('H2L', 'x')</th>\n",
       "      <th>('H2L', 'y')</th>\n",
       "      <th>...</th>\n",
       "      <th>('B2L', 'x')</th>\n",
       "      <th>('B2L', 'y')</th>\n",
       "      <th>('B3L', 'x')</th>\n",
       "      <th>('B3L', 'y')</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.548786</td>\n",
       "      <td>0.112236</td>\n",
       "      <td>-0.540907</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>-0.529858</td>\n",
       "      <td>-0.181602</td>\n",
       "      <td>-0.747827</td>\n",
       "      <td>0.149123</td>\n",
       "      <td>-0.710679</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044805</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>-0.038578</td>\n",
       "      <td>0.514353</td>\n",
       "      <td>0.100965</td>\n",
       "      <td>0.388717</td>\n",
       "      <td>-0.312793</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>-1.101565</td>\n",
       "      <td>-0.044794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.482077</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.028834</td>\n",
       "      <td>-0.582440</td>\n",
       "      <td>-0.207048</td>\n",
       "      <td>-0.668882</td>\n",
       "      <td>0.113342</td>\n",
       "      <td>-0.703076</td>\n",
       "      <td>0.193675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.159608</td>\n",
       "      <td>0.034803</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.157796</td>\n",
       "      <td>0.404489</td>\n",
       "      <td>-0.221796</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>-1.113008</td>\n",
       "      <td>-0.043997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.450080</td>\n",
       "      <td>0.049053</td>\n",
       "      <td>-0.440243</td>\n",
       "      <td>-0.054138</td>\n",
       "      <td>-0.528842</td>\n",
       "      <td>-0.160720</td>\n",
       "      <td>-0.569911</td>\n",
       "      <td>0.151780</td>\n",
       "      <td>-0.693194</td>\n",
       "      <td>0.200619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>0.053453</td>\n",
       "      <td>0.121334</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>0.211477</td>\n",
       "      <td>0.309930</td>\n",
       "      <td>-0.173742</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.125919</td>\n",
       "      <td>-0.021143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.475029</td>\n",
       "      <td>0.197571</td>\n",
       "      <td>-0.442460</td>\n",
       "      <td>0.083932</td>\n",
       "      <td>-0.512553</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>-0.567005</td>\n",
       "      <td>0.301382</td>\n",
       "      <td>-0.638720</td>\n",
       "      <td>0.339618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247065</td>\n",
       "      <td>-0.103355</td>\n",
       "      <td>0.106983</td>\n",
       "      <td>0.308025</td>\n",
       "      <td>0.251704</td>\n",
       "      <td>0.207961</td>\n",
       "      <td>-0.120525</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.140175</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.752387</td>\n",
       "      <td>0.366234</td>\n",
       "      <td>-0.831011</td>\n",
       "      <td>0.349049</td>\n",
       "      <td>-0.851251</td>\n",
       "      <td>0.240722</td>\n",
       "      <td>-0.831911</td>\n",
       "      <td>0.449172</td>\n",
       "      <td>-0.865292</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240064</td>\n",
       "      <td>-0.133487</td>\n",
       "      <td>0.068078</td>\n",
       "      <td>0.244615</td>\n",
       "      <td>0.214397</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>-0.087988</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.141927</td>\n",
       "      <td>-0.010592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888745</th>\n",
       "      <td>-0.492518</td>\n",
       "      <td>0.659527</td>\n",
       "      <td>-0.417676</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>-0.214989</td>\n",
       "      <td>0.320447</td>\n",
       "      <td>-0.337849</td>\n",
       "      <td>0.605044</td>\n",
       "      <td>-0.139779</td>\n",
       "      <td>0.545643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085691</td>\n",
       "      <td>-0.155232</td>\n",
       "      <td>-0.048431</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.201474</td>\n",
       "      <td>-0.268812</td>\n",
       "      <td>-0.016173</td>\n",
       "      <td>-0.247205</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>0.112877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888746</th>\n",
       "      <td>-0.448187</td>\n",
       "      <td>0.812045</td>\n",
       "      <td>-0.659524</td>\n",
       "      <td>0.741433</td>\n",
       "      <td>-0.512479</td>\n",
       "      <td>0.470148</td>\n",
       "      <td>-0.250138</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.561267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139846</td>\n",
       "      <td>-0.060972</td>\n",
       "      <td>-0.089506</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>-0.134636</td>\n",
       "      <td>-0.035160</td>\n",
       "      <td>0.508157</td>\n",
       "      <td>1.494835</td>\n",
       "      <td>0.179761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888747</th>\n",
       "      <td>-0.406025</td>\n",
       "      <td>0.836672</td>\n",
       "      <td>-0.612106</td>\n",
       "      <td>0.699109</td>\n",
       "      <td>-0.628093</td>\n",
       "      <td>0.482054</td>\n",
       "      <td>-0.134997</td>\n",
       "      <td>0.733382</td>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.444807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134693</td>\n",
       "      <td>-0.095315</td>\n",
       "      <td>-0.073009</td>\n",
       "      <td>0.159937</td>\n",
       "      <td>0.206434</td>\n",
       "      <td>0.087911</td>\n",
       "      <td>0.063541</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>1.465933</td>\n",
       "      <td>0.347291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888748</th>\n",
       "      <td>-0.396969</td>\n",
       "      <td>0.830068</td>\n",
       "      <td>-0.605613</td>\n",
       "      <td>0.692534</td>\n",
       "      <td>-0.622839</td>\n",
       "      <td>0.475791</td>\n",
       "      <td>-0.118199</td>\n",
       "      <td>0.726301</td>\n",
       "      <td>0.149024</td>\n",
       "      <td>0.437928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135024</td>\n",
       "      <td>-0.092783</td>\n",
       "      <td>-0.065171</td>\n",
       "      <td>0.163794</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.095640</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>1.463561</td>\n",
       "      <td>0.351864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888749</th>\n",
       "      <td>-0.562182</td>\n",
       "      <td>0.767972</td>\n",
       "      <td>-0.796726</td>\n",
       "      <td>0.626523</td>\n",
       "      <td>-0.629683</td>\n",
       "      <td>0.385079</td>\n",
       "      <td>-0.232601</td>\n",
       "      <td>0.662477</td>\n",
       "      <td>0.045754</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145755</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>-0.078891</td>\n",
       "      <td>0.162557</td>\n",
       "      <td>0.202525</td>\n",
       "      <td>0.140486</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>-0.121312</td>\n",
       "      <td>1.452635</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888750 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ('nose', 'x')  ('nose', 'y')  ('H1R', 'x')  ('H1R', 'y')  \\\n",
       "0           -0.548786       0.112236     -0.540907      0.008330   \n",
       "1           -0.482077       0.078642     -0.465556     -0.028834   \n",
       "2           -0.450080       0.049053     -0.440243     -0.054138   \n",
       "3           -0.475029       0.197571     -0.442460      0.083932   \n",
       "4           -0.752387       0.366234     -0.831011      0.349049   \n",
       "...               ...            ...           ...           ...   \n",
       "888745      -0.492518       0.659527     -0.417676      0.547214   \n",
       "888746      -0.448187       0.812045     -0.659524      0.741433   \n",
       "888747      -0.406025       0.836672     -0.612106      0.699109   \n",
       "888748      -0.396969       0.830068     -0.605613      0.692534   \n",
       "888749      -0.562182       0.767972     -0.796726      0.626523   \n",
       "\n",
       "        ('H2R', 'x')  ('H2R', 'y')  ('H1L', 'x')  ('H1L', 'y')  ('H2L', 'x')  \\\n",
       "0          -0.529858     -0.181602     -0.747827      0.149123     -0.710679   \n",
       "1          -0.582440     -0.207048     -0.668882      0.113342     -0.703076   \n",
       "2          -0.528842     -0.160720     -0.569911      0.151780     -0.693194   \n",
       "3          -0.512553     -0.021408     -0.567005      0.301382     -0.638720   \n",
       "4          -0.851251      0.240722     -0.831911      0.449172     -0.865292   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "888745     -0.214989      0.320447     -0.337849      0.605044     -0.139779   \n",
       "888746     -0.512479      0.470148     -0.250138      0.787986      0.014362   \n",
       "888747     -0.628093      0.482054     -0.134997      0.733382      0.130084   \n",
       "888748     -0.622839      0.475791     -0.118199      0.726301      0.149024   \n",
       "888749     -0.629683      0.385079     -0.232601      0.662477      0.045754   \n",
       "\n",
       "        ('H2L', 'y')  ...  ('B2L', 'x')  ('B2L', 'y')  ('B3L', 'x')  \\\n",
       "0           0.254334  ...     -0.044805      0.177647     -0.038578   \n",
       "1           0.193675  ...      0.045100      0.159608      0.034803   \n",
       "2           0.200619  ...      0.152834      0.053453      0.121334   \n",
       "3           0.339618  ...      0.247065     -0.103355      0.106983   \n",
       "4           0.473742  ...      0.240064     -0.133487      0.068078   \n",
       "...              ...  ...           ...           ...           ...   \n",
       "888745      0.545643  ...     -0.085691     -0.155232     -0.048431   \n",
       "888746      0.561267  ...     -0.139846     -0.060972     -0.089506   \n",
       "888747      0.444807  ...     -0.134693     -0.095315     -0.073009   \n",
       "888748      0.437928  ...     -0.135024     -0.092783     -0.065171   \n",
       "888749      0.379777  ...     -0.145755     -0.026286     -0.078891   \n",
       "\n",
       "        ('B3L', 'y')  ('tail', 'x')  ('tail', 'y')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0           0.514353       0.100965       0.388717    -0.312793     0.256370   \n",
       "1           0.519004       0.157796       0.404489    -0.221796     0.256370   \n",
       "2           0.439152       0.211477       0.309930    -0.173742    -0.498993   \n",
       "3           0.308025       0.251704       0.207961    -0.120525    -0.498993   \n",
       "4           0.244615       0.214397       0.144363    -0.087988    -0.498993   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "888745      0.045442       0.201474      -0.268812    -0.016173    -0.247205   \n",
       "888746      0.050696       0.203059      -0.134636    -0.035160     0.508157   \n",
       "888747      0.159937       0.206434       0.087911     0.063541     0.004582   \n",
       "888748      0.163794       0.216320       0.095640     0.073733     0.130476   \n",
       "888749      0.162557       0.202525       0.140486     0.040079    -0.121312   \n",
       "\n",
       "        ('S1', 'x')  ('S1', 'y')  \n",
       "0         -1.101565    -0.044794  \n",
       "1         -1.113008    -0.043997  \n",
       "2         -1.125919    -0.021143  \n",
       "3         -1.140175     0.008063  \n",
       "4         -1.141927    -0.010592  \n",
       "...             ...          ...  \n",
       "888745     1.495610     0.112877  \n",
       "888746     1.494835     0.179761  \n",
       "888747     1.465933     0.347291  \n",
       "888748     1.463561     0.351864  \n",
       "888749     1.452635     0.405521  \n",
       "\n",
       "[888750 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(filtered_data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "\n",
    "# Assuming df is your dataframe with limb coordinate changes\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Transform the training set\n",
    "train_data_scaled = scaler.transform(train_data)\n",
    "train_data = pd.DataFrame(train_data_scaled.reshape(train_data.shape), columns=train_data.columns)\n",
    "\n",
    "# When you're ready to test the model, transform the test set\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "test_data = pd.DataFrame(test_data_scaled.reshape(test_data.shape), columns=test_data.columns)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0311a319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:38.576397Z",
     "start_time": "2023-10-20T12:56:38.233122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, seq_size, train_data, pred_window)\n",
    "val_dataset = SeqDataset(device, seq_size, val_data, pred_window)\n",
    "test_dataset = SeqDataset(device, seq_size, test_data, pred_window)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549e679c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:05.842633Z",
     "start_time": "2023-10-20T13:22:05.833632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74f0e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:12.646245Z",
     "start_time": "2023-10-20T13:22:12.523793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 28\n",
      "Output size: 28\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8050171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:34:55.248289Z",
     "start_time": "2023-10-20T13:22:19.431166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   7%|████▊                                                             | 919/12655 [00:12<02:37, 74.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m train_loss       \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     adam(\n\u001b[0;32m    164\u001b[0m         params_with_grad,\n\u001b[0;32m    165\u001b[0m         grads,\n\u001b[0;32m    166\u001b[0m         exp_avgs,\n\u001b[0;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    169\u001b[0m         state_steps,\n\u001b[0;32m    170\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    171\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    172\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    173\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    174\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    175\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    177\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    178\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    179\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    180\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    181\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    182\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m func(params,\n\u001b[0;32m    312\u001b[0m      grads,\n\u001b[0;32m    313\u001b[0m      exp_avgs,\n\u001b[0;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    316\u001b[0m      state_steps,\n\u001b[0;32m    317\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    318\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    319\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    320\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    321\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    322\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    323\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    324\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    325\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    326\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    327\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:490\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Handle complex parameters\u001b[39;00m\n\u001b[0;32m    489\u001b[0m device_grads \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_grads]\n\u001b[1;32m--> 490\u001b[0m device_exp_avgs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avgs]\n\u001b[0;32m    491\u001b[0m device_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avg_sqs]\n\u001b[0;32m    492\u001b[0m device_max_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_max_exp_avg_sqs]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:490\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Handle complex parameters\u001b[39;00m\n\u001b[0;32m    489\u001b[0m device_grads \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_grads]\n\u001b[1;32m--> 490\u001b[0m device_exp_avgs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avgs]\n\u001b[0;32m    491\u001b[0m device_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avg_sqs]\n\u001b[0;32m    492\u001b[0m device_max_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_max_exp_avg_sqs]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../Models/model_md_norm_dropped_cols.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c48716-54f6-4978-b1f4-47dfd3c671a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_md_norm_dropped_cols.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294297b2-da36-46bb-9658-cab24e82ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3339/3339 [00:49<00:00, 67.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e69552d-afef-40d1-915f-797db364162a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_baseline.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01db2ef4-05c9-4c46-9060-ea8264f0680e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:36<00:00, 91.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 952.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c36f2af-6e7e-488b-8152-ce7c3c35eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_baseline_dropped_cols.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "263f0e2b-7b60-4f19-b5c4-394d4d4d45d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:40<00:00, 82.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1070.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e47bb0-86ff-41c4-af89-c17292c38fa0",
   "metadata": {},
   "source": [
    "## Longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36a7c755-9370-4b60-85cf-5f5a2f5d8542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 25 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 25\n",
    "shift_size     = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ba3e9f8-3a65-417b-92cb-fe82c8d7f3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, dataframe, seq_size, pred_window, shift_size):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.seq_size = seq_size  # Input sequence length\n",
    "        self.shift_size = 25  # Shift for the start of each new sequence\n",
    "        self.pred_window = pred_window  # Additional frames for prediction\n",
    "        self.dataframe = dataframe\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        # The total number of sequences is adjusted for shifting the sequence start by self.shift_size\n",
    "        return (len(self.dataframe) - self.seq_size - self.pred_window) // self.shift_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the actual starting index for the sequence based on the shift size\n",
    "        start_idx = idx * self.shift_size\n",
    "        end_idx = start_idx + self.seq_size\n",
    "        target_end_idx = end_idx + self.pred_window\n",
    "\n",
    "        # Ensure we don't exceed the bounds of the dataframe\n",
    "        if target_end_idx > len(self.dataframe):\n",
    "            target_end_idx = len(self.dataframe)\n",
    "            end_idx = target_end_idx - self.pred_window\n",
    "\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[start_idx:end_idx].values,\n",
    "                              dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.dataframe.iloc[end_idx:target_end_idx].values,\n",
    "                                  dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "265103df-17b6-4cb5-ab25-bc54e0d0f8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>('H1L', 'y')</th>\n",
       "      <th>('H2L', 'x')</th>\n",
       "      <th>('H2L', 'y')</th>\n",
       "      <th>...</th>\n",
       "      <th>('B2L', 'x')</th>\n",
       "      <th>('B2L', 'y')</th>\n",
       "      <th>('B3L', 'x')</th>\n",
       "      <th>('B3L', 'y')</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.548786</td>\n",
       "      <td>0.112236</td>\n",
       "      <td>-0.540907</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>-0.529858</td>\n",
       "      <td>-0.181602</td>\n",
       "      <td>-0.747827</td>\n",
       "      <td>0.149123</td>\n",
       "      <td>-0.710679</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044805</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>-0.038578</td>\n",
       "      <td>0.514353</td>\n",
       "      <td>0.100965</td>\n",
       "      <td>0.388717</td>\n",
       "      <td>-0.312793</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>-1.101565</td>\n",
       "      <td>-0.044794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.482077</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.028834</td>\n",
       "      <td>-0.582440</td>\n",
       "      <td>-0.207048</td>\n",
       "      <td>-0.668882</td>\n",
       "      <td>0.113342</td>\n",
       "      <td>-0.703076</td>\n",
       "      <td>0.193675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.159608</td>\n",
       "      <td>0.034803</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.157796</td>\n",
       "      <td>0.404489</td>\n",
       "      <td>-0.221796</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>-1.113008</td>\n",
       "      <td>-0.043997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.450080</td>\n",
       "      <td>0.049053</td>\n",
       "      <td>-0.440243</td>\n",
       "      <td>-0.054138</td>\n",
       "      <td>-0.528842</td>\n",
       "      <td>-0.160720</td>\n",
       "      <td>-0.569911</td>\n",
       "      <td>0.151780</td>\n",
       "      <td>-0.693194</td>\n",
       "      <td>0.200619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>0.053453</td>\n",
       "      <td>0.121334</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>0.211477</td>\n",
       "      <td>0.309930</td>\n",
       "      <td>-0.173742</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.125919</td>\n",
       "      <td>-0.021143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.475029</td>\n",
       "      <td>0.197571</td>\n",
       "      <td>-0.442460</td>\n",
       "      <td>0.083932</td>\n",
       "      <td>-0.512553</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>-0.567005</td>\n",
       "      <td>0.301382</td>\n",
       "      <td>-0.638720</td>\n",
       "      <td>0.339618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247065</td>\n",
       "      <td>-0.103355</td>\n",
       "      <td>0.106983</td>\n",
       "      <td>0.308025</td>\n",
       "      <td>0.251704</td>\n",
       "      <td>0.207961</td>\n",
       "      <td>-0.120525</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.140175</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.752387</td>\n",
       "      <td>0.366234</td>\n",
       "      <td>-0.831011</td>\n",
       "      <td>0.349049</td>\n",
       "      <td>-0.851251</td>\n",
       "      <td>0.240722</td>\n",
       "      <td>-0.831911</td>\n",
       "      <td>0.449172</td>\n",
       "      <td>-0.865292</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240064</td>\n",
       "      <td>-0.133487</td>\n",
       "      <td>0.068078</td>\n",
       "      <td>0.244615</td>\n",
       "      <td>0.214397</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>-0.087988</td>\n",
       "      <td>-0.498993</td>\n",
       "      <td>-1.141927</td>\n",
       "      <td>-0.010592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888745</th>\n",
       "      <td>-0.492518</td>\n",
       "      <td>0.659527</td>\n",
       "      <td>-0.417676</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>-0.214989</td>\n",
       "      <td>0.320447</td>\n",
       "      <td>-0.337849</td>\n",
       "      <td>0.605044</td>\n",
       "      <td>-0.139779</td>\n",
       "      <td>0.545643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085691</td>\n",
       "      <td>-0.155232</td>\n",
       "      <td>-0.048431</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.201474</td>\n",
       "      <td>-0.268812</td>\n",
       "      <td>-0.016173</td>\n",
       "      <td>-0.247205</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>0.112877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888746</th>\n",
       "      <td>-0.448187</td>\n",
       "      <td>0.812045</td>\n",
       "      <td>-0.659524</td>\n",
       "      <td>0.741433</td>\n",
       "      <td>-0.512479</td>\n",
       "      <td>0.470148</td>\n",
       "      <td>-0.250138</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.561267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139846</td>\n",
       "      <td>-0.060972</td>\n",
       "      <td>-0.089506</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>-0.134636</td>\n",
       "      <td>-0.035160</td>\n",
       "      <td>0.508157</td>\n",
       "      <td>1.494835</td>\n",
       "      <td>0.179761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888747</th>\n",
       "      <td>-0.406025</td>\n",
       "      <td>0.836672</td>\n",
       "      <td>-0.612106</td>\n",
       "      <td>0.699109</td>\n",
       "      <td>-0.628093</td>\n",
       "      <td>0.482054</td>\n",
       "      <td>-0.134997</td>\n",
       "      <td>0.733382</td>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.444807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134693</td>\n",
       "      <td>-0.095315</td>\n",
       "      <td>-0.073009</td>\n",
       "      <td>0.159937</td>\n",
       "      <td>0.206434</td>\n",
       "      <td>0.087911</td>\n",
       "      <td>0.063541</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>1.465933</td>\n",
       "      <td>0.347291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888748</th>\n",
       "      <td>-0.396969</td>\n",
       "      <td>0.830068</td>\n",
       "      <td>-0.605613</td>\n",
       "      <td>0.692534</td>\n",
       "      <td>-0.622839</td>\n",
       "      <td>0.475791</td>\n",
       "      <td>-0.118199</td>\n",
       "      <td>0.726301</td>\n",
       "      <td>0.149024</td>\n",
       "      <td>0.437928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135024</td>\n",
       "      <td>-0.092783</td>\n",
       "      <td>-0.065171</td>\n",
       "      <td>0.163794</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.095640</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>1.463561</td>\n",
       "      <td>0.351864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888749</th>\n",
       "      <td>-0.562182</td>\n",
       "      <td>0.767972</td>\n",
       "      <td>-0.796726</td>\n",
       "      <td>0.626523</td>\n",
       "      <td>-0.629683</td>\n",
       "      <td>0.385079</td>\n",
       "      <td>-0.232601</td>\n",
       "      <td>0.662477</td>\n",
       "      <td>0.045754</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145755</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>-0.078891</td>\n",
       "      <td>0.162557</td>\n",
       "      <td>0.202525</td>\n",
       "      <td>0.140486</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>-0.121312</td>\n",
       "      <td>1.452635</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888750 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ('nose', 'x')  ('nose', 'y')  ('H1R', 'x')  ('H1R', 'y')  \\\n",
       "0           -0.548786       0.112236     -0.540907      0.008330   \n",
       "1           -0.482077       0.078642     -0.465556     -0.028834   \n",
       "2           -0.450080       0.049053     -0.440243     -0.054138   \n",
       "3           -0.475029       0.197571     -0.442460      0.083932   \n",
       "4           -0.752387       0.366234     -0.831011      0.349049   \n",
       "...               ...            ...           ...           ...   \n",
       "888745      -0.492518       0.659527     -0.417676      0.547214   \n",
       "888746      -0.448187       0.812045     -0.659524      0.741433   \n",
       "888747      -0.406025       0.836672     -0.612106      0.699109   \n",
       "888748      -0.396969       0.830068     -0.605613      0.692534   \n",
       "888749      -0.562182       0.767972     -0.796726      0.626523   \n",
       "\n",
       "        ('H2R', 'x')  ('H2R', 'y')  ('H1L', 'x')  ('H1L', 'y')  ('H2L', 'x')  \\\n",
       "0          -0.529858     -0.181602     -0.747827      0.149123     -0.710679   \n",
       "1          -0.582440     -0.207048     -0.668882      0.113342     -0.703076   \n",
       "2          -0.528842     -0.160720     -0.569911      0.151780     -0.693194   \n",
       "3          -0.512553     -0.021408     -0.567005      0.301382     -0.638720   \n",
       "4          -0.851251      0.240722     -0.831911      0.449172     -0.865292   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "888745     -0.214989      0.320447     -0.337849      0.605044     -0.139779   \n",
       "888746     -0.512479      0.470148     -0.250138      0.787986      0.014362   \n",
       "888747     -0.628093      0.482054     -0.134997      0.733382      0.130084   \n",
       "888748     -0.622839      0.475791     -0.118199      0.726301      0.149024   \n",
       "888749     -0.629683      0.385079     -0.232601      0.662477      0.045754   \n",
       "\n",
       "        ('H2L', 'y')  ...  ('B2L', 'x')  ('B2L', 'y')  ('B3L', 'x')  \\\n",
       "0           0.254334  ...     -0.044805      0.177647     -0.038578   \n",
       "1           0.193675  ...      0.045100      0.159608      0.034803   \n",
       "2           0.200619  ...      0.152834      0.053453      0.121334   \n",
       "3           0.339618  ...      0.247065     -0.103355      0.106983   \n",
       "4           0.473742  ...      0.240064     -0.133487      0.068078   \n",
       "...              ...  ...           ...           ...           ...   \n",
       "888745      0.545643  ...     -0.085691     -0.155232     -0.048431   \n",
       "888746      0.561267  ...     -0.139846     -0.060972     -0.089506   \n",
       "888747      0.444807  ...     -0.134693     -0.095315     -0.073009   \n",
       "888748      0.437928  ...     -0.135024     -0.092783     -0.065171   \n",
       "888749      0.379777  ...     -0.145755     -0.026286     -0.078891   \n",
       "\n",
       "        ('B3L', 'y')  ('tail', 'x')  ('tail', 'y')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0           0.514353       0.100965       0.388717    -0.312793     0.256370   \n",
       "1           0.519004       0.157796       0.404489    -0.221796     0.256370   \n",
       "2           0.439152       0.211477       0.309930    -0.173742    -0.498993   \n",
       "3           0.308025       0.251704       0.207961    -0.120525    -0.498993   \n",
       "4           0.244615       0.214397       0.144363    -0.087988    -0.498993   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "888745      0.045442       0.201474      -0.268812    -0.016173    -0.247205   \n",
       "888746      0.050696       0.203059      -0.134636    -0.035160     0.508157   \n",
       "888747      0.159937       0.206434       0.087911     0.063541     0.004582   \n",
       "888748      0.163794       0.216320       0.095640     0.073733     0.130476   \n",
       "888749      0.162557       0.202525       0.140486     0.040079    -0.121312   \n",
       "\n",
       "        ('S1', 'x')  ('S1', 'y')  \n",
       "0         -1.101565    -0.044794  \n",
       "1         -1.113008    -0.043997  \n",
       "2         -1.125919    -0.021143  \n",
       "3         -1.140175     0.008063  \n",
       "4         -1.141927    -0.010592  \n",
       "...             ...          ...  \n",
       "888745     1.495610     0.112877  \n",
       "888746     1.494835     0.179761  \n",
       "888747     1.465933     0.347291  \n",
       "888748     1.463561     0.351864  \n",
       "888749     1.452635     0.405521  \n",
       "\n",
       "[888750 rows x 28 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(filtered_data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "\n",
    "# Assuming df is your dataframe with limb coordinate changes\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Transform the training set\n",
    "train_data_scaled = scaler.transform(train_data)\n",
    "train_data = pd.DataFrame(train_data_scaled.reshape(train_data.shape), columns=train_data.columns)\n",
    "\n",
    "# When you're ready to test the model, transform the test set\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "test_data = pd.DataFrame(test_data_scaled.reshape(test_data.shape), columns=test_data.columns)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "824cb0e9-93d8-4457-95e4-b3dc5c6c1de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, train_data, seq_size, pred_window, shift_size)\n",
    "val_dataset = SeqDataset(device, val_data, seq_size, pred_window, shift_size)\n",
    "test_dataset = SeqDataset(device, test_data, seq_size, pred_window, shift_size)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25a73678-be7c-4ee0-a9ef-3c63b829eac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d568148e-dc64-4d5f-a9d8-3e29f3fbee6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 28\n",
      "Output size: 28\n",
      "Model(\n",
      "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b669d39-e5ea-4f90-a915-39c09537e7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 59.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9146\n",
      "Val loss: 1.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 61.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8705\n",
      "Val loss: 1.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 59.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8620\n",
      "Val loss: 1.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:07<00:00, 66.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8560\n",
      "Val loss: 1.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 60.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8527\n",
      "Val loss: 1.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 59.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8502\n",
      "Val loss: 1.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 62.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8479\n",
      "Val loss: 1.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 60.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8461\n",
      "Val loss: 1.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 59.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8448\n",
      "Val loss: 1.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:08<00:00, 60.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8434\n",
      "Val loss: 1.1299\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "\n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../Models/model_md_norm_pred_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76bf4235-8dd3-45e8-b36c-5ef549019bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"../Models/model_mc_norm_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "753e8911-f935-47f5-8438-2bf10a21acb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [00:01<00:00, 75.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37afeea0-6ef1-456f-9b00-2ce69e67bfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4dad792-a127-4ccc-a051-0cbe6fc65a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 133/133 [00:01<00:00, 102.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11223.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5445754-3ce5-4e95-86ce-f659d7a2ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"../Models/model_cc_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00485426-3bc6-4302-8779-3532639d27a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [00:04<00:00, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 120.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
