{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314601d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:25.653417Z",
     "start_time": "2023-10-20T12:55:25.646418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a71d10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:31.527035Z",
     "start_time": "2023-10-20T12:55:31.513362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3b682f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:45.380476Z",
     "start_time": "2023-10-20T12:55:38.145357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('nose', 'likelihood')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H1R', 'likelihood')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H2R', 'likelihood')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>...</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('tail', 'likelihood')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S2', 'likelihood')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "      <th>('S1', 'likelihood')</th>\n",
       "      <th>mouse_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444275</td>\n",
       "      <td>2.021118</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>1.981354</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>4.448181</td>\n",
       "      <td>4.355835</td>\n",
       "      <td>0.997916</td>\n",
       "      <td>0.535675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.670120</td>\n",
       "      <td>0.212906</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>0.595001</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>3.630341</td>\n",
       "      <td>2.596069</td>\n",
       "      <td>0.993003</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.439880</td>\n",
       "      <td>3.892548</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.945496</td>\n",
       "      <td>3.524902</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>1.928741</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>0.970154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798141</td>\n",
       "      <td>1.392517</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>2.681183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986211</td>\n",
       "      <td>3.590607</td>\n",
       "      <td>2.148987</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.703064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>5.919373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>4.751312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>6.556610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855469</td>\n",
       "      <td>1.921738</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>2.977997</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.981083</td>\n",
       "      <td>3.765533</td>\n",
       "      <td>2.638062</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.169312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>20.999176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>17.283508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>13.850159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.927261</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>1.823181</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>1.339661</td>\n",
       "      <td>2.253326</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>3.207214</td>\n",
       "      <td>5.388489</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>3.782471</td>\n",
       "      <td>2.128571</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>8.150452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.424469</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>4.226929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>1.342590</td>\n",
       "      <td>4.823639</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.945129</td>\n",
       "      <td>3.831635</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.461548</td>\n",
       "      <td>1.584595</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>3.117249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.385101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>-0.049561</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>12.412659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>9.379395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>6.598083</td>\n",
       "      <td>2.645782</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>7.575562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155914</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>-0.301575</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.308044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214752</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.073730</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.488098</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053497</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.064789</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>-0.496552</td>\n",
       "      <td>-1.002960</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('nose', 'likelihood')  ('H1R', 'x')  \\\n",
       "0             0.000000       0.000000                0.999969      0.000000   \n",
       "1             0.444275       2.021118                0.999950      0.536194   \n",
       "2             0.439880       3.892548                0.999945      0.945496   \n",
       "3             7.703064       0.000000                0.999765      5.919373   \n",
       "4            17.169312       0.000000                0.999855     20.999176   \n",
       "...                ...            ...                     ...           ...   \n",
       "1102495       1.339661       2.253326                0.999232      3.207214   \n",
       "1102496       1.342590       4.823639                0.999680      1.945129   \n",
       "1102497      12.412659       0.000000                0.999622      9.379395   \n",
       "1102498       0.000000       0.000000                0.999570      0.000000   \n",
       "1102499       0.000000      -0.488098                0.999951      0.000000   \n",
       "\n",
       "         ('H1R', 'y')  ('H1R', 'likelihood')  ('H2R', 'x')  ('H2R', 'y')  \\\n",
       "0            0.000000               0.999760      0.000000      0.000000   \n",
       "1            1.981354               0.999568      4.448181      4.355835   \n",
       "2            3.524902               0.999638      1.928741      0.726379   \n",
       "3            0.000000               0.999534      4.751312      0.000000   \n",
       "4            0.000000               0.999252     17.283508      0.000000   \n",
       "...               ...                    ...           ...           ...   \n",
       "1102495      5.388489               0.999924      3.782471      2.128571   \n",
       "1102496      3.831635               0.999842      0.461548      1.584595   \n",
       "1102497      0.000000               0.999950      6.598083      2.645782   \n",
       "1102498      0.000000               0.999939      0.000000      0.000000   \n",
       "1102499     -0.053497               0.999773      0.000000      0.000000   \n",
       "\n",
       "         ('H2R', 'likelihood')  ('H1L', 'x')  ...  ('tail', 'x')  \\\n",
       "0                     0.996968      0.000000  ...       0.000000   \n",
       "1                     0.997916      0.535675  ...       1.670120   \n",
       "2                     0.999153      0.970154  ...       0.798141   \n",
       "3                     0.999468      6.556610  ...       1.855469   \n",
       "4                     0.998945     13.850159  ...       0.000000   \n",
       "...                        ...           ...  ...            ...   \n",
       "1102495               0.999492      8.150452  ...       0.582886   \n",
       "1102496               0.999562      3.117249  ...       0.348389   \n",
       "1102497               0.999656      7.575562  ...      -0.155914   \n",
       "1102498               0.999616      0.000000  ...       0.000000   \n",
       "1102499               0.998583      0.000000  ...       0.000000   \n",
       "\n",
       "         ('tail', 'y')  ('tail', 'likelihood')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0             0.000000                0.998689     0.000000     0.000000   \n",
       "1             0.212906                0.999059     0.595001     0.076477   \n",
       "2             1.392517                0.999419     2.681183     0.000000   \n",
       "3             1.921738                0.999285     2.977997     0.041992   \n",
       "4             4.927261                0.999156     0.000000     0.000000   \n",
       "...                ...                     ...          ...          ...   \n",
       "1102495       0.000000                0.999563     0.424469     0.375305   \n",
       "1102496       0.000000                0.999529     0.385101     0.000000   \n",
       "1102497      -1.260956                0.999215     0.496552    -0.301575   \n",
       "1102498      -0.214752                0.999225     0.000000    -0.073730   \n",
       "1102499      -1.064789                0.999358    -0.496552    -1.002960   \n",
       "\n",
       "         ('S2', 'likelihood')  ('S1', 'x')  ('S1', 'y')  ('S1', 'likelihood')  \\\n",
       "0                    0.994912     0.000000     0.000000              0.995648   \n",
       "1                    0.996069     3.630341     2.596069              0.993003   \n",
       "2                    0.986211     3.590607     2.148987              0.987800   \n",
       "3                    0.981083     3.765533     2.638062              0.994152   \n",
       "4                    0.983985     1.823181     0.067993              0.995609   \n",
       "...                       ...          ...          ...                   ...   \n",
       "1102495              0.998793     4.226929     0.000000              0.998882   \n",
       "1102496              0.998716     0.232422    -0.049561              0.998840   \n",
       "1102497              0.999035     0.308044     0.000000              0.998980   \n",
       "1102498              0.998865     0.000000     0.000000              0.998603   \n",
       "1102499              0.999527     0.000000     0.000000              0.998710   \n",
       "\n",
       "         mouse_no  \n",
       "0            11.4  \n",
       "1            11.4  \n",
       "2            11.4  \n",
       "3            11.4  \n",
       "4            11.4  \n",
       "...           ...  \n",
       "1102495      88.3  \n",
       "1102496      88.3  \n",
       "1102497      88.3  \n",
       "1102498      88.3  \n",
       "1102499      88.3  \n",
       "\n",
       "[1102500 rows x 43 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"C:/Users/Kieran/Documents/Master Thesis Data/Datasets/ChangeCoords\"\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "        \n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data = data.drop(columns = ['frame_number'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a785b79-9304-4d16-9002-f35298232989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>('H1L', 'y')</th>\n",
       "      <th>('H2L', 'x')</th>\n",
       "      <th>('H2L', 'y')</th>\n",
       "      <th>...</th>\n",
       "      <th>('B2L', 'x')</th>\n",
       "      <th>('B2L', 'y')</th>\n",
       "      <th>('B3L', 'x')</th>\n",
       "      <th>('B3L', 'y')</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444275</td>\n",
       "      <td>2.021118</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>1.981354</td>\n",
       "      <td>4.448181</td>\n",
       "      <td>4.355835</td>\n",
       "      <td>0.535675</td>\n",
       "      <td>1.918579</td>\n",
       "      <td>2.168060</td>\n",
       "      <td>3.959808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.721603</td>\n",
       "      <td>0.863861</td>\n",
       "      <td>0.081955</td>\n",
       "      <td>1.670120</td>\n",
       "      <td>0.212906</td>\n",
       "      <td>0.595001</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>3.630341</td>\n",
       "      <td>2.596069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.439880</td>\n",
       "      <td>3.892548</td>\n",
       "      <td>0.945496</td>\n",
       "      <td>3.524902</td>\n",
       "      <td>1.928741</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.970154</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>2.823761</td>\n",
       "      <td>3.261963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249634</td>\n",
       "      <td>1.100983</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.525070</td>\n",
       "      <td>0.798141</td>\n",
       "      <td>1.392517</td>\n",
       "      <td>2.681183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.590607</td>\n",
       "      <td>2.148987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.703064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.919373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.751312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.556610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491577</td>\n",
       "      <td>2.587845</td>\n",
       "      <td>3.322083</td>\n",
       "      <td>5.370407</td>\n",
       "      <td>1.855469</td>\n",
       "      <td>1.921738</td>\n",
       "      <td>2.977997</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>3.765533</td>\n",
       "      <td>2.638062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.169312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.999176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.283508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.850159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.907776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.244858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.321640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.927261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.823181</td>\n",
       "      <td>0.067993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>1.339661</td>\n",
       "      <td>2.253326</td>\n",
       "      <td>3.207214</td>\n",
       "      <td>5.388489</td>\n",
       "      <td>3.782471</td>\n",
       "      <td>2.128571</td>\n",
       "      <td>8.150452</td>\n",
       "      <td>1.492737</td>\n",
       "      <td>6.739807</td>\n",
       "      <td>2.576172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424469</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>4.226929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>1.342590</td>\n",
       "      <td>4.823639</td>\n",
       "      <td>1.945129</td>\n",
       "      <td>3.831635</td>\n",
       "      <td>0.461548</td>\n",
       "      <td>1.584595</td>\n",
       "      <td>3.117249</td>\n",
       "      <td>1.559113</td>\n",
       "      <td>3.390930</td>\n",
       "      <td>0.636566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203430</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047913</td>\n",
       "      <td>0.348389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>-0.049561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>12.412659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.379395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.598083</td>\n",
       "      <td>2.645782</td>\n",
       "      <td>7.575562</td>\n",
       "      <td>1.143738</td>\n",
       "      <td>9.298645</td>\n",
       "      <td>1.647430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121002</td>\n",
       "      <td>-0.018829</td>\n",
       "      <td>-0.317688</td>\n",
       "      <td>-0.513275</td>\n",
       "      <td>-0.155914</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>-0.301575</td>\n",
       "      <td>0.308044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.752960</td>\n",
       "      <td>-0.583069</td>\n",
       "      <td>-0.222778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.073730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.488098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-1.701813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.064789</td>\n",
       "      <td>-0.496552</td>\n",
       "      <td>-1.002960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('H1R', 'x')  ('H1R', 'y')  \\\n",
       "0             0.000000       0.000000      0.000000      0.000000   \n",
       "1             0.444275       2.021118      0.536194      1.981354   \n",
       "2             0.439880       3.892548      0.945496      3.524902   \n",
       "3             7.703064       0.000000      5.919373      0.000000   \n",
       "4            17.169312       0.000000     20.999176      0.000000   \n",
       "...                ...            ...           ...           ...   \n",
       "1102495       1.339661       2.253326      3.207214      5.388489   \n",
       "1102496       1.342590       4.823639      1.945129      3.831635   \n",
       "1102497      12.412659       0.000000      9.379395      0.000000   \n",
       "1102498       0.000000       0.000000      0.000000      0.000000   \n",
       "1102499       0.000000      -0.488098      0.000000     -0.053497   \n",
       "\n",
       "         ('H2R', 'x')  ('H2R', 'y')  ('H1L', 'x')  ('H1L', 'y')  ('H2L', 'x')  \\\n",
       "0            0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "1            4.448181      4.355835      0.535675      1.918579      2.168060   \n",
       "2            1.928741      0.726379      0.970154      0.231018      2.823761   \n",
       "3            4.751312      0.000000      6.556610      0.000000      4.600220   \n",
       "4           17.283508      0.000000     13.850159      0.000000     10.907776   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "1102495      3.782471      2.128571      8.150452      1.492737      6.739807   \n",
       "1102496      0.461548      1.584595      3.117249      1.559113      3.390930   \n",
       "1102497      6.598083      2.645782      7.575562      1.143738      9.298645   \n",
       "1102498      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "1102499      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "         ('H2L', 'y')  ...  ('B2L', 'x')  ('B2L', 'y')  ('B3L', 'x')  \\\n",
       "0            0.000000  ...      0.000000      0.000000      0.000000   \n",
       "1            3.959808  ...      0.682312      0.721603      0.863861   \n",
       "2            3.261963  ...      0.249634      1.100983      0.030807   \n",
       "3            0.000000  ...      0.491577      2.587845      3.322083   \n",
       "4            0.000000  ...      0.000000      1.244858      0.000000   \n",
       "...               ...  ...           ...           ...           ...   \n",
       "1102495      2.576172  ...      0.000000      0.000000      0.000000   \n",
       "1102496      0.636566  ...      0.203430      0.018829      0.000000   \n",
       "1102497      1.647430  ...     -0.121002     -0.018829     -0.317688   \n",
       "1102498      0.000000  ...      0.000000     -1.752960     -0.583069   \n",
       "1102499      0.000000  ...      0.000000      0.000000     -0.262146   \n",
       "\n",
       "         ('B3L', 'y')  ('tail', 'x')  ('tail', 'y')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0            0.000000       0.000000       0.000000     0.000000     0.000000   \n",
       "1            0.081955       1.670120       0.212906     0.595001     0.076477   \n",
       "2            0.525070       0.798141       1.392517     2.681183     0.000000   \n",
       "3            5.370407       1.855469       1.921738     2.977997     0.041992   \n",
       "4            4.321640       0.000000       4.927261     0.000000     0.000000   \n",
       "...               ...            ...            ...          ...          ...   \n",
       "1102495      0.000000       0.582886       0.000000     0.424469     0.375305   \n",
       "1102496     -0.047913       0.348389       0.000000     0.385101     0.000000   \n",
       "1102497     -0.513275      -0.155914      -1.260956     0.496552    -0.301575   \n",
       "1102498     -0.222778       0.000000      -0.214752     0.000000    -0.073730   \n",
       "1102499     -1.701813       0.000000      -1.064789    -0.496552    -1.002960   \n",
       "\n",
       "         ('S1', 'x')  ('S1', 'y')  \n",
       "0           0.000000     0.000000  \n",
       "1           3.630341     2.596069  \n",
       "2           3.590607     2.148987  \n",
       "3           3.765533     2.638062  \n",
       "4           1.823181     0.067993  \n",
       "...              ...          ...  \n",
       "1102495     4.226929     0.000000  \n",
       "1102496     0.232422    -0.049561  \n",
       "1102497     0.308044     0.000000  \n",
       "1102498     0.000000     0.000000  \n",
       "1102499     0.000000     0.000000  \n",
       "\n",
       "[1102500 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = data.filter(regex='x|y')\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f3a88-ae6a-4630-b5e2-05936e2ccf0a",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32c90502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:24.250214Z",
     "start_time": "2023-10-20T12:56:24.236867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 25 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b49113e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:30.971456Z",
     "start_time": "2023-10-20T12:56:30.957509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, seq_size, dataframe, pred_window):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device      = device\n",
    "        self.seq_size    = seq_size\n",
    "        self.dataframe   = dataframe\n",
    "        self.pred_window = pred_window\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.seq_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[idx:idx + self.seq_size].values, dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[idx + self.pred_window:idx + self.seq_size + self.pred_window].values, dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0026de6d-f242-4941-90a4-2e2fafbe95f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>('H1L', 'y')</th>\n",
       "      <th>('H2L', 'x')</th>\n",
       "      <th>('H2L', 'y')</th>\n",
       "      <th>...</th>\n",
       "      <th>('B2L', 'x')</th>\n",
       "      <th>('B2L', 'y')</th>\n",
       "      <th>('B3L', 'x')</th>\n",
       "      <th>('B3L', 'y')</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030136</td>\n",
       "      <td>0.202595</td>\n",
       "      <td>0.042665</td>\n",
       "      <td>0.222129</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.578631</td>\n",
       "      <td>0.048169</td>\n",
       "      <td>0.233582</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.540242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>0.067129</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.033871</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>0.466434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.390002</td>\n",
       "      <td>0.075345</td>\n",
       "      <td>0.395007</td>\n",
       "      <td>0.169979</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>0.288733</td>\n",
       "      <td>0.445079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.102393</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.032235</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>0.093670</td>\n",
       "      <td>0.152935</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.430928</td>\n",
       "      <td>0.386141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523368</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.472476</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.418980</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.590458</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.470434</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031513</td>\n",
       "      <td>0.240598</td>\n",
       "      <td>0.171238</td>\n",
       "      <td>0.329391</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>0.129277</td>\n",
       "      <td>0.169875</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.473975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.166596</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>1.676498</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1.524541</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1.247368</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>1.115588</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.115766</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.265072</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.331494</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.218798</td>\n",
       "      <td>0.012413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888745</th>\n",
       "      <td>-0.102628</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-0.036128</td>\n",
       "      <td>0.013897</td>\n",
       "      <td>-0.153636</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.025617</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.006168</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.006652</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.015013</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.061922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888746</th>\n",
       "      <td>-0.011756</td>\n",
       "      <td>1.254310</td>\n",
       "      <td>-0.906201</td>\n",
       "      <td>1.062190</td>\n",
       "      <td>-1.062746</td>\n",
       "      <td>0.695131</td>\n",
       "      <td>0.118954</td>\n",
       "      <td>1.505482</td>\n",
       "      <td>0.543744</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.023209</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.260603</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.035382</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.188087</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.013610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888747</th>\n",
       "      <td>-0.246973</td>\n",
       "      <td>1.353019</td>\n",
       "      <td>-0.400740</td>\n",
       "      <td>1.087945</td>\n",
       "      <td>-1.114228</td>\n",
       "      <td>1.109223</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>1.051559</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.623966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.548576</td>\n",
       "      <td>-0.106311</td>\n",
       "      <td>-0.352955</td>\n",
       "      <td>-0.292687</td>\n",
       "      <td>-0.362257</td>\n",
       "      <td>-0.051875</td>\n",
       "      <td>-0.398471</td>\n",
       "      <td>-0.793082</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888748</th>\n",
       "      <td>-0.014951</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.034310</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-0.048630</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036248</td>\n",
       "      <td>-0.015400</td>\n",
       "      <td>-0.011372</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.005296</td>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.013234</td>\n",
       "      <td>-0.084949</td>\n",
       "      <td>-0.013207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888749</th>\n",
       "      <td>-0.486055</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.635974</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-0.156169</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.378760</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.374706</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.026396</td>\n",
       "      <td>-0.037322</td>\n",
       "      <td>-0.216338</td>\n",
       "      <td>-0.085561</td>\n",
       "      <td>-0.199456</td>\n",
       "      <td>-0.142378</td>\n",
       "      <td>-0.171161</td>\n",
       "      <td>-0.168680</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888750 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ('nose', 'x')  ('nose', 'y')  ('H1R', 'x')  ('H1R', 'y')  \\\n",
       "0           -0.000052       0.000199     -0.000146      0.000217   \n",
       "1            0.030136       0.202595      0.042665      0.222129   \n",
       "2            0.029837       0.390002      0.075345      0.395007   \n",
       "3            0.523368       0.000199      0.472476      0.000217   \n",
       "4            1.166596       0.000199      1.676498      0.000217   \n",
       "...               ...            ...           ...           ...   \n",
       "888745      -0.102628       0.000575     -0.036128      0.013897   \n",
       "888746      -0.011756       1.254310     -0.906201      1.062190   \n",
       "888747      -0.246973       1.353019     -0.400740      1.087945   \n",
       "888748      -0.014951       0.000199     -0.034310      0.000217   \n",
       "888749      -0.486055       0.000199     -0.635974      0.000217   \n",
       "\n",
       "        ('H2R', 'x')  ('H2R', 'y')  ('H1L', 'x')  ('H1L', 'y')  ('H2L', 'x')  \\\n",
       "0          -0.000170      0.000244     -0.000078      0.000233     -0.000089   \n",
       "1           0.392238      0.578631      0.048169      0.233582      0.221666   \n",
       "2           0.169979      0.096696      0.087301      0.028331      0.288733   \n",
       "3           0.418980      0.000244      0.590458      0.000233      0.470434   \n",
       "4           1.524541      0.000244      1.247368      0.000233      1.115588   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "888745     -0.153636      0.000603      0.004996      0.025617      0.002674   \n",
       "888746     -1.062746      0.695131      0.118954      1.505482      0.543744   \n",
       "888747     -1.114228      1.109223     -0.000078      1.051559     -0.000089   \n",
       "888748     -0.048630      0.000244     -0.000078      0.000233     -0.000089   \n",
       "888749     -0.156169      0.000244     -0.378760      0.000233     -0.374706   \n",
       "\n",
       "        ('H2L', 'y')  ...  ('B2L', 'x')  ('B2L', 'y')  ('B3L', 'x')  \\\n",
       "0           0.000257  ...      0.000040      0.000056     -0.000052   \n",
       "1           0.540242  ...      0.043725      0.067129      0.044490   \n",
       "2           0.445079  ...      0.016023      0.102393      0.001537   \n",
       "3           0.000257  ...      0.031513      0.240598      0.171238   \n",
       "4           0.000257  ...      0.000040      0.115766     -0.000052   \n",
       "...              ...  ...           ...           ...           ...   \n",
       "888745      0.020083  ...      0.000040     -0.006168     -0.000052   \n",
       "888746      0.715300  ...      0.000040     -0.023209     -0.000052   \n",
       "888747      0.623966  ...      0.000040     -0.548576     -0.106311   \n",
       "888748      0.000257  ...     -0.036248     -0.015400     -0.011372   \n",
       "888749      0.000257  ...     -0.006283     -0.026396     -0.037322   \n",
       "\n",
       "        ('B3L', 'y')  ('tail', 'x')  ('tail', 'y')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0           0.000033      -0.000031      -0.000021    -0.000087     0.000075   \n",
       "1           0.005059       0.093737       0.014304     0.033871     0.005106   \n",
       "2           0.032235       0.044780       0.093670     0.152935     0.000075   \n",
       "3           0.329391       0.104144       0.129277     0.169875     0.002837   \n",
       "4           0.265072      -0.000031       0.331494    -0.000087     0.000075   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "888745     -0.006652      -0.000031      -0.002033    -0.000087    -0.015013   \n",
       "888746     -0.260603      -0.000031      -0.035382    -0.000087    -0.188087   \n",
       "888747     -0.352955      -0.292687      -0.362257    -0.051875    -0.398471   \n",
       "888748     -0.008974      -0.009010      -0.005296    -0.013693    -0.013234   \n",
       "888749     -0.216338      -0.085561      -0.199456    -0.142378    -0.171161   \n",
       "\n",
       "        ('S1', 'x')  ('S1', 'y')  \n",
       "0         -0.000024     0.000202  \n",
       "1          0.435697     0.466434  \n",
       "2          0.430928     0.386141  \n",
       "3          0.451923     0.473975  \n",
       "4          0.218798     0.012413  \n",
       "...             ...          ...  \n",
       "888745    -0.000024     0.061922  \n",
       "888746    -0.000024     0.013610  \n",
       "888747    -0.793082     0.000202  \n",
       "888748    -0.084949    -0.013207  \n",
       "888749    -0.168680     0.000202  \n",
       "\n",
       "[888750 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(filtered_data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "\n",
    "# Assuming df is your dataframe with limb coordinate changes\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Transform the training set\n",
    "train_data_scaled = scaler.transform(train_data)\n",
    "train_data = pd.DataFrame(train_data_scaled.reshape(train_data.shape), columns=train_data.columns)\n",
    "\n",
    "# When you're ready to test the model, transform the test set\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "test_data = pd.DataFrame(test_data_scaled.reshape(test_data.shape), columns=test_data.columns)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0311a319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:38.576397Z",
     "start_time": "2023-10-20T12:56:38.233122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, seq_size, train_data, pred_window)\n",
    "val_dataset = SeqDataset(device, seq_size, val_data, pred_window)\n",
    "test_dataset = SeqDataset(device, seq_size, test_data, pred_window)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "549e679c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:05.842633Z",
     "start_time": "2023-10-20T13:22:05.833632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74f0e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:12.646245Z",
     "start_time": "2023-10-20T13:22:12.523793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 28\n",
      "Output size: 28\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8050171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:34:55.248289Z",
     "start_time": "2023-10-20T13:22:19.431166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [06:04<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8354\n",
      "Val loss: 1.3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [05:00<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8238\n",
      "Val loss: 1.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:51<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8199\n",
      "Val loss: 1.3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:40<00:00, 45.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8182\n",
      "Val loss: 1.3037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:43<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8173\n",
      "Val loss: 1.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:45<00:00, 44.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8168\n",
      "Val loss: 1.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:45<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8164\n",
      "Val loss: 1.2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:52<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8160\n",
      "Val loss: 1.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:39<00:00, 45.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8157\n",
      "Val loss: 1.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████| 12655/12655 [04:50<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8156\n",
      "Val loss: 1.3004\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../Models/model_cc_norm_dropped_cols.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83c48716-54f6-4978-b1f4-47dfd3c671a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"../Models/model_cc_norm_dropped_cols.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "294297b2-da36-46bb-9658-cab24e82ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3339/3339 [01:04<00:00, 51.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e69552d-afef-40d1-915f-797db364162a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_baseline.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01db2ef4-05c9-4c46-9060-ea8264f0680e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:36<00:00, 91.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 952.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c36f2af-6e7e-488b-8152-ce7c3c35eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_baseline_dropped_cols.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "263f0e2b-7b60-4f19-b5c4-394d4d4d45d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:40<00:00, 82.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1070.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e47bb0-86ff-41c4-af89-c17292c38fa0",
   "metadata": {},
   "source": [
    "## Longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a7c755-9370-4b60-85cf-5f5a2f5d8542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 50 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 25\n",
    "shift_size     = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba3e9f8-3a65-417b-92cb-fe82c8d7f3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, dataframe, seq_size, pred_window, shift_size):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.seq_size = seq_size  # Input sequence length\n",
    "        self.shift_size = 25  # Shift for the start of each new sequence\n",
    "        self.pred_window = pred_window  # Additional frames for prediction\n",
    "        self.dataframe = dataframe\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        # The total number of sequences is adjusted for shifting the sequence start by self.shift_size\n",
    "        return (len(self.dataframe) - self.seq_size - self.pred_window) // self.shift_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the actual starting index for the sequence based on the shift size\n",
    "        start_idx = idx * self.shift_size\n",
    "        end_idx = start_idx + self.seq_size\n",
    "        target_end_idx = end_idx + self.pred_window\n",
    "\n",
    "        # Ensure we don't exceed the bounds of the dataframe\n",
    "        if target_end_idx > len(self.dataframe):\n",
    "            target_end_idx = len(self.dataframe)\n",
    "            end_idx = target_end_idx - self.pred_window\n",
    "\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[start_idx:end_idx].values,\n",
    "                              dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[start_idx+self.pred_window:target_end_idx].values,\n",
    "                                  dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265103df-17b6-4cb5-ab25-bc54e0d0f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(filtered_data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "\n",
    "# Assuming df is your dataframe with limb coordinate changes\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Transform the training set\n",
    "train_data_scaled = scaler.transform(train_data)\n",
    "train_data = pd.DataFrame(train_data_scaled.reshape(train_data.shape), columns=train_data.columns)\n",
    "\n",
    "# When you're ready to test the model, transform the test set\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "test_data = pd.DataFrame(test_data_scaled.reshape(test_data.shape), columns=test_data.columns)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824cb0e9-93d8-4457-95e4-b3dc5c6c1de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, train_data, seq_size, pred_window, shift_size)\n",
    "val_dataset = SeqDataset(device, val_data, seq_size, pred_window, shift_size)\n",
    "test_dataset = SeqDataset(device, test_data, seq_size, pred_window, shift_size)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a73678-be7c-4ee0-a9ef-3c63b829eac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d568148e-dc64-4d5f-a9d8-3e29f3fbee6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 43\n",
      "Output size: 28\n",
      "Model(\n",
      "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b669d39-e5ea-4f90-a915-39c09537e7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:18<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.9945\n",
      "Val loss: 240.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8696\n",
      "Val loss: 240.0997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:21<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8464\n",
      "Val loss: 240.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.8402\n",
      "Val loss: 240.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7916\n",
      "Val loss: 240.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:18<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7906\n",
      "Val loss: 240.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:18<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7785\n",
      "Val loss: 240.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:17<00:00, 28.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.7246\n",
      "Val loss: 240.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:16<00:00, 30.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.6477\n",
      "Val loss: 239.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:17<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 139.6562\n",
      "Val loss: 239.9908\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../Models/model_cc_pred_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37afeea0-6ef1-456f-9b00-2ce69e67bfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/model_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4dad792-a127-4ccc-a051-0cbe6fc65a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 133/133 [00:01<00:00, 102.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11223.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5445754-3ce5-4e95-86ce-f659d7a2ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"../Models/model_cc_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00485426-3bc6-4302-8779-3532639d27a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [00:04<00:00, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 120.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
