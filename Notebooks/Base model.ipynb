{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314601d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:25.653417Z",
     "start_time": "2023-10-20T12:55:25.646418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a71d10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:31.527035Z",
     "start_time": "2023-10-20T12:55:31.513362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b682f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:55:45.380476Z",
     "start_time": "2023-10-20T12:55:38.145357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('nose', 'x')</th>\n",
       "      <th>('nose', 'y')</th>\n",
       "      <th>('nose', 'likelihood')</th>\n",
       "      <th>('H1R', 'x')</th>\n",
       "      <th>('H1R', 'y')</th>\n",
       "      <th>('H1R', 'likelihood')</th>\n",
       "      <th>('H2R', 'x')</th>\n",
       "      <th>('H2R', 'y')</th>\n",
       "      <th>('H2R', 'likelihood')</th>\n",
       "      <th>('H1L', 'x')</th>\n",
       "      <th>...</th>\n",
       "      <th>('tail', 'x')</th>\n",
       "      <th>('tail', 'y')</th>\n",
       "      <th>('tail', 'likelihood')</th>\n",
       "      <th>('S2', 'x')</th>\n",
       "      <th>('S2', 'y')</th>\n",
       "      <th>('S2', 'likelihood')</th>\n",
       "      <th>('S1', 'x')</th>\n",
       "      <th>('S1', 'y')</th>\n",
       "      <th>('S1', 'likelihood')</th>\n",
       "      <th>mouse_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.501312</td>\n",
       "      <td>72.446838</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>76.267792</td>\n",
       "      <td>76.465271</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>54.404541</td>\n",
       "      <td>76.934204</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>99.304657</td>\n",
       "      <td>...</td>\n",
       "      <td>-94.751236</td>\n",
       "      <td>-99.595276</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>-45.061890</td>\n",
       "      <td>-37.560608</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>292.150818</td>\n",
       "      <td>318.674744</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.315247</td>\n",
       "      <td>71.871887</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>73.173645</td>\n",
       "      <td>75.850555</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>55.222382</td>\n",
       "      <td>78.693970</td>\n",
       "      <td>0.997916</td>\n",
       "      <td>96.209991</td>\n",
       "      <td>...</td>\n",
       "      <td>-96.711456</td>\n",
       "      <td>-101.978439</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>-48.097229</td>\n",
       "      <td>-40.080200</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>295.781158</td>\n",
       "      <td>321.270813</td>\n",
       "      <td>0.993003</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.164520</td>\n",
       "      <td>73.615448</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>70.528534</td>\n",
       "      <td>77.226471</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>53.560516</td>\n",
       "      <td>77.271362</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>93.589539</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.503922</td>\n",
       "      <td>-102.734909</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>-49.006653</td>\n",
       "      <td>-42.229187</td>\n",
       "      <td>0.986211</td>\n",
       "      <td>299.371765</td>\n",
       "      <td>323.419800</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.102051</td>\n",
       "      <td>70.977386</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>72.682373</td>\n",
       "      <td>74.588409</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>54.546295</td>\n",
       "      <td>74.633301</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>96.380615</td>\n",
       "      <td>...</td>\n",
       "      <td>-101.413986</td>\n",
       "      <td>-103.451233</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>-49.794189</td>\n",
       "      <td>-44.825256</td>\n",
       "      <td>0.981083</td>\n",
       "      <td>303.137299</td>\n",
       "      <td>326.057861</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.448181</td>\n",
       "      <td>70.909393</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>91.858368</td>\n",
       "      <td>74.520416</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>70.006622</td>\n",
       "      <td>74.565308</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>108.407593</td>\n",
       "      <td>...</td>\n",
       "      <td>-103.237167</td>\n",
       "      <td>-98.591965</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>-51.617371</td>\n",
       "      <td>-44.893250</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>304.960480</td>\n",
       "      <td>326.125854</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102495</th>\n",
       "      <td>92.895691</td>\n",
       "      <td>-22.675415</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>85.470825</td>\n",
       "      <td>-11.074768</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>75.502136</td>\n",
       "      <td>-8.060303</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>84.703430</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.412476</td>\n",
       "      <td>116.388947</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>-33.810913</td>\n",
       "      <td>56.276733</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>525.421082</td>\n",
       "      <td>367.743622</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102496</th>\n",
       "      <td>94.005859</td>\n",
       "      <td>-17.802216</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>87.183533</td>\n",
       "      <td>-7.193573</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>75.731262</td>\n",
       "      <td>-6.426147</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>87.588257</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.296509</td>\n",
       "      <td>116.438507</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>-33.658234</td>\n",
       "      <td>56.326294</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>525.653503</td>\n",
       "      <td>367.694061</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102497</th>\n",
       "      <td>106.110474</td>\n",
       "      <td>-17.802216</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>96.254883</td>\n",
       "      <td>-7.193573</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>82.021301</td>\n",
       "      <td>-3.780365</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>94.855774</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.760468</td>\n",
       "      <td>115.177551</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>-33.469727</td>\n",
       "      <td>56.024719</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>525.961548</td>\n",
       "      <td>367.694061</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102498</th>\n",
       "      <td>106.110474</td>\n",
       "      <td>-17.802216</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>96.254883</td>\n",
       "      <td>-7.193573</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>82.021301</td>\n",
       "      <td>-3.780365</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>94.855774</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.760468</td>\n",
       "      <td>114.962799</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>-33.469727</td>\n",
       "      <td>55.950989</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>525.961548</td>\n",
       "      <td>367.694061</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102499</th>\n",
       "      <td>106.110474</td>\n",
       "      <td>-18.290314</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>96.254883</td>\n",
       "      <td>-7.247070</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>82.021301</td>\n",
       "      <td>-3.780365</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>94.855774</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.760468</td>\n",
       "      <td>113.898010</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>-33.966278</td>\n",
       "      <td>54.948029</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>525.961548</td>\n",
       "      <td>367.694061</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102500 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ('nose', 'x')  ('nose', 'y')  ('nose', 'likelihood')  ('H1R', 'x')  \\\n",
       "0            97.501312      72.446838                0.999969     76.267792   \n",
       "1            94.315247      71.871887                0.999950     73.173645   \n",
       "2            91.164520      73.615448                0.999945     70.528534   \n",
       "3            95.102051      70.977386                0.999765     72.682373   \n",
       "4           110.448181      70.909393                0.999855     91.858368   \n",
       "...                ...            ...                     ...           ...   \n",
       "1102495      92.895691     -22.675415                0.999232     85.470825   \n",
       "1102496      94.005859     -17.802216                0.999680     87.183533   \n",
       "1102497     106.110474     -17.802216                0.999622     96.254883   \n",
       "1102498     106.110474     -17.802216                0.999570     96.254883   \n",
       "1102499     106.110474     -18.290314                0.999951     96.254883   \n",
       "\n",
       "         ('H1R', 'y')  ('H1R', 'likelihood')  ('H2R', 'x')  ('H2R', 'y')  \\\n",
       "0           76.465271               0.999760     54.404541     76.934204   \n",
       "1           75.850555               0.999568     55.222382     78.693970   \n",
       "2           77.226471               0.999638     53.560516     77.271362   \n",
       "3           74.588409               0.999534     54.546295     74.633301   \n",
       "4           74.520416               0.999252     70.006622     74.565308   \n",
       "...               ...                    ...           ...           ...   \n",
       "1102495    -11.074768               0.999924     75.502136     -8.060303   \n",
       "1102496     -7.193573               0.999842     75.731262     -6.426147   \n",
       "1102497     -7.193573               0.999950     82.021301     -3.780365   \n",
       "1102498     -7.193573               0.999939     82.021301     -3.780365   \n",
       "1102499     -7.247070               0.999773     82.021301     -3.780365   \n",
       "\n",
       "         ('H2R', 'likelihood')  ('H1L', 'x')  ...  ('tail', 'x')  \\\n",
       "0                     0.996968     99.304657  ...     -94.751236   \n",
       "1                     0.997916     96.209991  ...     -96.711456   \n",
       "2                     0.999153     93.589539  ...     -99.503922   \n",
       "3                     0.999468     96.380615  ...    -101.413986   \n",
       "4                     0.998945    108.407593  ...    -103.237167   \n",
       "...                        ...           ...  ...            ...   \n",
       "1102495               0.999492     84.703430  ...     -24.412476   \n",
       "1102496               0.999562     87.588257  ...     -24.296509   \n",
       "1102497               0.999656     94.855774  ...     -24.760468   \n",
       "1102498               0.999616     94.855774  ...     -24.760468   \n",
       "1102499               0.998583     94.855774  ...     -24.760468   \n",
       "\n",
       "         ('tail', 'y')  ('tail', 'likelihood')  ('S2', 'x')  ('S2', 'y')  \\\n",
       "0           -99.595276                0.998689   -45.061890   -37.560608   \n",
       "1          -101.978439                0.999059   -48.097229   -40.080200   \n",
       "2          -102.734909                0.999419   -49.006653   -42.229187   \n",
       "3          -103.451233                0.999285   -49.794189   -44.825256   \n",
       "4           -98.591965                0.999156   -51.617371   -44.893250   \n",
       "...                ...                     ...          ...          ...   \n",
       "1102495     116.388947                0.999563   -33.810913    56.276733   \n",
       "1102496     116.438507                0.999529   -33.658234    56.326294   \n",
       "1102497     115.177551                0.999215   -33.469727    56.024719   \n",
       "1102498     114.962799                0.999225   -33.469727    55.950989   \n",
       "1102499     113.898010                0.999358   -33.966278    54.948029   \n",
       "\n",
       "         ('S2', 'likelihood')  ('S1', 'x')  ('S1', 'y')  ('S1', 'likelihood')  \\\n",
       "0                    0.994912   292.150818   318.674744              0.995648   \n",
       "1                    0.996069   295.781158   321.270813              0.993003   \n",
       "2                    0.986211   299.371765   323.419800              0.987800   \n",
       "3                    0.981083   303.137299   326.057861              0.994152   \n",
       "4                    0.983985   304.960480   326.125854              0.995609   \n",
       "...                       ...          ...          ...                   ...   \n",
       "1102495              0.998793   525.421082   367.743622              0.998882   \n",
       "1102496              0.998716   525.653503   367.694061              0.998840   \n",
       "1102497              0.999035   525.961548   367.694061              0.998980   \n",
       "1102498              0.998865   525.961548   367.694061              0.998603   \n",
       "1102499              0.999527   525.961548   367.694061              0.998710   \n",
       "\n",
       "         mouse_no  \n",
       "0            11.4  \n",
       "1            11.4  \n",
       "2            11.4  \n",
       "3            11.4  \n",
       "4            11.4  \n",
       "...           ...  \n",
       "1102495      88.3  \n",
       "1102496      88.3  \n",
       "1102497      88.3  \n",
       "1102498      88.3  \n",
       "1102499      88.3  \n",
       "\n",
       "[1102500 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"C:/Users/Kieran/Documents/Master Thesis Data/Datasets/MouseCentric\"\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "        \n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data = data.drop(columns = ['frame_number'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f3a88-ae6a-4630-b5e2-05936e2ccf0a",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c90502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:24.250214Z",
     "start_time": "2023-10-20T12:56:24.236867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 25 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b49113e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:30.971456Z",
     "start_time": "2023-10-20T12:56:30.957509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, seq_size, dataframe, pred_window):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device      = device\n",
    "        self.seq_size    = seq_size\n",
    "        self.dataframe   = dataframe\n",
    "        self.pred_window = pred_window\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.seq_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[idx:idx + self.seq_size].values, dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[idx + self.pred_window:idx + self.seq_size + self.pred_window].values, dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0311a319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T12:56:38.576397Z",
     "start_time": "2023-10-20T12:56:38.233122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, seq_size, train_data, pred_window)\n",
    "val_dataset = SeqDataset(device, seq_size, val_data, pred_window)\n",
    "test_dataset = SeqDataset(device, seq_size, test_data, pred_window)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "549e679c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:05.842633Z",
     "start_time": "2023-10-20T13:22:05.833632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b74f0e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:22:12.646245Z",
     "start_time": "2023-10-20T13:22:12.523793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 43\n",
      "Output size: 28\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8050171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:34:55.248289Z",
     "start_time": "2023-10-20T13:22:19.431166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|                                                                    | 5/12655 [00:00<10:24, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|                                                                   | 11/12655 [00:00<09:32, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|                                                                   | 18/12655 [00:00<08:23, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▏                                                                  | 24/12655 [00:01<07:54, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▏                                                                  | 32/12655 [00:01<06:53, 30.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▏                                                                  | 36/12655 [00:01<06:33, 32.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▏                                                                  | 44/12655 [00:01<07:12, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▎                                                                  | 50/12655 [00:01<07:51, 26.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▎                                                                  | 57/12655 [00:02<07:23, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   0%|▎                                                                  | 60/12655 [00:02<07:41, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10:   1%|▎                                                                  | 64/12655 [00:02<07:58, 26.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "torch.Size([64, 25, 43])\n",
      "Train loss: 72.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m in_seq, target_seq \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     30\u001b[0m         out_seq, _  \u001b[38;5;241m=\u001b[39m model(in_seq)\n\u001b[0;32m     31\u001b[0m         loss        \u001b[38;5;241m=\u001b[39m criterion(out_seq, target_seq)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36mSeqDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 14\u001b[0m     in_seq \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     target_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_data\u001b[38;5;241m.\u001b[39miloc[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_window:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_window]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m in_seq, target_seq\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        # torch.save(model.state_dict(), \"model_pred_3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83c48716-54f6-4978-b1f4-47dfd3c671a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_pred_2.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "294297b2-da36-46bb-9658-cab24e82ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:35<00:00, 94.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 905.8601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "#     x_coord = target_seq.cpu()[0, -1][::2]\n",
    "#     y_coord = target_seq.cpu()[0, -1][1::2]\n",
    "#     x_coord_pred = out_seq.cpu().detach().numpy()[0, -1][::2]\n",
    "#     y_coord_pred = out_seq.cpu().detach().numpy()[0, -1][1::2]\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     plt.scatter(x_coord, y_coord, label = \"Target\")\n",
    "#     plt.scatter(x_coord_pred, y_coord_pred, label = \"Prediction\")\n",
    "#     plt.xlabel('X Coordinates')\n",
    "#     plt.ylabel('Y Coordinates')\n",
    "#     plt.title(\"Output test\")\n",
    "#     plt.legend()\n",
    "#     plt.xlim(-800, 800)\n",
    "#     plt.ylim(-650, 650)\n",
    "#     plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "#     plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "#     plt.show()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e69552d-afef-40d1-915f-797db364162a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_baseline.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01db2ef4-05c9-4c46-9060-ea8264f0680e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:36<00:00, 91.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 952.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c36f2af-6e7e-488b-8152-ce7c3c35eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(28, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_baseline_dropped_cols.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "263f0e2b-7b60-4f19-b5c4-394d4d4d45d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3340/3340 [00:40<00:00, 82.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1070.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e47bb0-86ff-41c4-af89-c17292c38fa0",
   "metadata": {},
   "source": [
    "## Longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36a7c755-9370-4b60-85cf-5f5a2f5d8542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_prob   = 0.5\n",
    "embedding_size = 32\n",
    "epoch_num      = 10\n",
    "hidden_size    = 16\n",
    "layer_num      = 2\n",
    "learning_rate  = 1e-3\n",
    "seq_size       = 50 #25 frames is equal to 1 second of video, maybe use 50?\n",
    "pred_window    = 25\n",
    "shift_size     = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ba3e9f8-3a65-417b-92cb-fe82c8d7f3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, device, dataframe, seq_size, pred_window, shift_size):\n",
    "        super(SeqDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.seq_size = seq_size  # Input sequence length\n",
    "        self.shift_size = 25  # Shift for the start of each new sequence\n",
    "        self.pred_window = pred_window  # Additional frames for prediction\n",
    "        self.dataframe = dataframe\n",
    "        self.target_data = dataframe.filter(regex='x|y')\n",
    "\n",
    "    def __len__(self):\n",
    "        # The total number of sequences is adjusted for shifting the sequence start by self.shift_size\n",
    "        return (len(self.dataframe) - self.seq_size - self.pred_window) // self.shift_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the actual starting index for the sequence based on the shift size\n",
    "        start_idx = idx * self.shift_size\n",
    "        end_idx = start_idx + self.seq_size\n",
    "        target_end_idx = end_idx + self.pred_window\n",
    "\n",
    "        # Ensure we don't exceed the bounds of the dataframe\n",
    "        if target_end_idx > len(self.dataframe):\n",
    "            target_end_idx = len(self.dataframe)\n",
    "            end_idx = target_end_idx - self.pred_window\n",
    "\n",
    "        in_seq = torch.tensor(self.dataframe.iloc[start_idx:end_idx].values,\n",
    "                              dtype=torch.float, device=self.device)\n",
    "        target_seq = torch.tensor(self.target_data.iloc[start_idx+self.pred_window:target_end_idx].values,\n",
    "                                  dtype=torch.float, device=self.device)\n",
    "        return in_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "824cb0e9-93d8-4457-95e4-b3dc5c6c1de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test using the full video sizes (so that videos are not split into different sets)\n",
    "train_data, test_data = train_test_split(data, test_size= 11250*int(0.2*98), shuffle=False)\n",
    "n_train_vids = len(train_data)/11250\n",
    "train_data, val_data = train_test_split(train_data, test_size = 11250 * int(0.1 * n_train_vids), shuffle=False)\n",
    "\n",
    "# Create SeqDataset instances for the train, validation, and test sets\n",
    "train_dataset = SeqDataset(device, train_data, seq_size, pred_window, shift_size)\n",
    "val_dataset = SeqDataset(device, val_data, seq_size, pred_window, shift_size)\n",
    "test_dataset = SeqDataset(device, test_data, seq_size, pred_window, shift_size)\n",
    "\n",
    "# Create DataLoader instances for batching\n",
    "batch_size = 64  # Adjust to your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25a73678-be7c-4ee0-a9ef-3c63b829eac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_prob, hidden_size, layer_num, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru       = nn.GRU(input_size, hidden_size, layer_num, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear    = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, in_sequence, hidden_state=None):\n",
    "#         embedding_seq            = self.embedding(in_sequence)\n",
    "        hidden_seq, hidden_state = self.gru(in_sequence, hidden_state)\n",
    "        out_seq                  = self.linear(hidden_seq)\n",
    "        return out_seq, hidden_state\n",
    "    \n",
    "    def draw(self, in_sequence, logit_temp=1.0):\n",
    "        out_seq, _  = self(in_sequence)\n",
    "        prob_dist   = torch.softmax(out_seq[0, -1] / logit_temp, 0)\n",
    "        rand_sample = torch.multinomial(prob_dist, 1).item()                   \n",
    "        return rand_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d568148e-dc64-4d5f-a9d8-3e29f3fbee6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 43\n",
      "Output size: 28\n",
      "Model(\n",
      "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = next(iter(train_loader))[0].size(-1)\n",
    "print(\"Input size:\", input_size)\n",
    "output_size = next(iter(train_loader))[1].size(-1)\n",
    "print(\"Output size:\", output_size)\n",
    "model = Model(dropout_prob, hidden_size, layer_num, input_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b669d39-e5ea-4f90-a915-39c09537e7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 73.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 14392.6587\n",
      "Val loss: 13985.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 13924.6838\n",
      "Val loss: 13575.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 80.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 13517.0019\n",
      "Val loss: 13193.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 77.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 13130.1789\n",
      "Val loss: 12827.7930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 75.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 12759.8280\n",
      "Val loss: 12476.2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 77.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 12403.3501\n",
      "Val loss: 12136.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 76.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 12057.0882\n",
      "Val loss: 11808.4731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:05<00:00, 87.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 11722.7404\n",
      "Val loss: 11489.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:07<00:00, 69.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 11397.5210\n",
      "Val loss: 11181.2699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████| 506/506 [00:06<00:00, 81.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 11082.7356\n",
      "Val loss: 10884.0909\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for in_seq, target_seq in tqdm(train_loader, desc=f\"Epoch {epoch}/{epoch_num}\"):\n",
    "        \n",
    "        out_seq, _  = model(in_seq)\n",
    "        loss        = criterion(out_seq, target_seq)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    train_loss       /= len(train_loader)\n",
    "    # train_perplexity  = np.exp(train_loss)\n",
    "    print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for in_seq, target_seq in val_loader:\n",
    "            out_seq, _  = model(in_seq)\n",
    "            loss        = criterion(out_seq, target_seq)\n",
    "            val_loss   += loss.item()\n",
    "\n",
    "    val_loss       /= len(val_loader)\n",
    "    # val_perplexity  = np.exp(val_loss)\n",
    "    print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"C:/Users/Kieran/Documents/Master Thesis Data/Models/model_pred_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37afeea0-6ef1-456f-9b00-2ce69e67bfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Model(\n",
       "  (gru): GRU(43, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=16, out_features=28, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"C:/Users/Kieran/Documents/Master Thesis Data/Models/model_pred_25.pt\"))\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4dad792-a127-4ccc-a051-0cbe6fc65a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 133/133 [00:01<00:00, 102.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11223.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "for in_seq, target_seq in tqdm(test_loader):\n",
    "    out_seq, _ = model(in_seq)\n",
    "    loss = criterion(out_seq, target_seq)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
